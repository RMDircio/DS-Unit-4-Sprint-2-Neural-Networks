{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Alex_Kim_DS_422_Gradient_Descent_Backprop_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F2orT1i7RyS9"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfbCqTnHRyMu",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 2, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "rp5dsZnVRyND",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation & Gradient Descent (Prepare)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pshNjtdRyNM",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "* <a href=\"#p1\">Part 1</a>: Explain the intutition behind backproprogation\n",
        "* <a href=\"#p2\">Part 2</a>: Implement gradient descent + backpropagation on a feedforward neural network. \n",
        "* <a href=\"#p3\">Part 3</a>: Introduce the Keras Sequential Model API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzOKAwPMRyNR",
        "colab_type": "text"
      },
      "source": [
        "## Summary of Yesterday\n",
        "\n",
        "Yesterday, we learned about some of the principal components of Neural Networks: Neurons, Weights, Activation Functions, and layers (input, output, & hidden). Today, we will reinforce our understanding of those components and introduce the mechanics of training a neural network. Feed-forward neural networks, such as multi-layer perceptrons (MLPs), are almost always trained using some variation of gradient descent where the gradient has been calculated by backpropagation.\n",
        "\n",
        "<center><img src=\"https://cdn-images-1.medium.com/max/1600/1*_M4bZyuwaGby6KMiYVYXvg.jpeg\" width=\"400\"></center>\n",
        "\n",
        "* WEIGHTS ARE PARAMERTERS\n",
        "\n",
        "* HIDDEN LAYERS GET INFO FROM INPUT + HIDDEN NODES\n",
        "\n",
        "* FEATURES (DATASET MAKE THE NUMBER OF NURONS IN STRUCTIRE - WE CAN NOT CHANGE THAT\n",
        "\n",
        "* DENSE NN - MEANS EACH INPUT NODE IS CONNECTED TO EVERY NODE IN THE NEXT  LAYER (HIDDEN LAYER)\n",
        "\n",
        "* SOME NN HAVE SKIP LAYERS THAT SKIP A LAYER\n",
        "\n",
        "* TO HAVE MORE HIDDEN LAYERS VS HAVING LOST OF NUERONS IN A SMALLER NUMBER OF HIDDEN LAYERS\n",
        "\n",
        "* BIAS -> LIKE HUMAN BRAIN , INPUTS EXESEED LEVEL THEN NURON WILL FIRE , EACH NODE HAS A LEVEL/\"CAP\" of when IT NEEDS TO FIRE TO NEXT LAYER\n",
        "\n",
        "  * BIAS NEGATIVE = SIGMOID MOVES TO THE RIGHT\n",
        "  * BIAS POSTIVE = SIGMOID MOVE TO THE LEFT\n",
        "-------------------------------------------------------------------------------\n",
        "- There are three kinds of layers: input, hidden, and output layers.\n",
        "- Each layer is made up of **n** individual neurons (aka activation units) which have a corresponding weight and bias.\n",
        "- Signal is passed from layer to layer through a network by:\n",
        " - Taking in inputs from the training data (or previous layer)\n",
        " - Multiplying each input by its corresponding weight (think arrow/connecting line)\n",
        " - Adding a bias to this weighted some of inputs and weights\n",
        " - Activating this weighted sum + bias by squishifying it with sigmoid or some other activation function. With a single perceptron with three inputs, calculating the output from the node is done like so:\n",
        "\\begin{align}\n",
        " y = sigmoid(\\sum(weight_{1}input_{1} + weight_{2}input_{2} + weight_{3}input_{3}) + bias)\n",
        "\\end{align}\n",
        " - this final activated value is the signal that gets passed onto the next layer of the network.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDDvb1BCRyNW",
        "colab_type": "text"
      },
      "source": [
        "## Training a Neural Network: *Formal Summary*\n",
        "\n",
        "------------- 2. IS INOPUT LAYER TO NEXT LAYER - HIDDEN--------------\n",
        "------- 4. GRADENT FOR ALL WEIGHTS\n",
        "-----------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "0. Pick a network architecture\n",
        "   - No. of input units = No. of features\n",
        "   - No. of output units = Number of Classes (or expected targets)\n",
        "   - Select the number of hidden layers and number of neurons within each hidden layer\n",
        "1. Randomly initialize weights\n",
        "2. Implement forward propagation to get $h_{\\theta}(x^{(i)})$ for any $x^{(i)}$\n",
        "3. Implement code to compute a cost function $J(\\theta)$\n",
        "4. Implement backpropagation to compute partial derivatives- IN OTHER WORDS COMPUTE THE GRADIENCE $\\frac{\\delta}{\\delta\\theta_{jk}^{l}}{J(\\theta)}$\n",
        "5. Use gradient descent (or other advanced optimizer) with backpropagation to minimize - IN OTHER WORDS OPTIMIZE THE GRADIENCE IN REALTION TO THE WEIGHTS $J(\\theta)$ as a function of parameters $\\theta\\$\n",
        "6. Repeat steps 2 - 5 until cost function is 'minimized' or some other stopping criteria is met. One pass over steps 2 - 5 is called an iteration or epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "8TrHiA8HRyNc",
        "colab_type": "text"
      },
      "source": [
        "## Calculating *\"cost\"*, *\"loss\"* or *\"error\"*\n",
        "\n",
        "\n",
        "* 4 INPUT NODES = 4 COLUMNS IN DF [N, 4] = FEATURE MATRIX\n",
        "* NN NOTATION\n",
        "  * X ZERO IS AROUND - CONNECTED TO NEXT LAYERS\n",
        "  * SUBSCRIP 1 = FEATURE NUMBER\n",
        "  * SUBSCRIPT 2 = NERURON NUMBER\n",
        "  * SUPER SCRIPT = LAYER NUMBER\n",
        "* HEAVEST WEIGHT DEPENDS ON NUREONS - 1ST HIDDEN LAYER HAS 4 INPUTS SO FOR WEIGHTS FOR EACH NODE IN THE 1ST HIDDEN LAYER -- weights can  BE IN MATRICIES\n",
        "\n",
        "* X MATIRIC [N, 4] MATRIC MULUPLY BY WEIGHT IN HIDDEN LATER 1 [4,5] WHICH GIVES [N, 5]\n",
        "  * THEN THE NEW MATIRX GETS MULTIPLED IN THE NEXT LAYER [N, 7] \n",
        "  * ACTIVATION FUNCTIONS HAPPEN INBETWEEN THE MULTIPLIING ---GET TO  [N, 7]\n",
        "  * FINALLY AT THE END WE GET Y HAT IS AN ARRAY OF PREDICTIONS\n",
        "\n",
        "* LOSS FUNCTION IS PARAMTERS IN ALL LAYERS\n",
        "  * EXPRESSED AS DIFFENECE - NOT SUBTRACTIONN - PREDICTION AND ACTUAL N^2\n",
        "  * MEARURE OF HOW BAD THE PREDICTIONS ARE\n",
        "  * TRYS TO MINIMISE LOCAL MINIUMS\n",
        "  * loss funmction is averaged over all neurons - only get 1 value\n",
        "  * loss function used to see how bad things are\n",
        "  * 1 number measure how bad or good the NN is ACOROSS THE ENTIRE DATA SET\n",
        "\n",
        "-------------------------------------------------------------------------------\n",
        "We've talked about how in order to evaluate a network's performance, the data is \"fed forward\" until predictions are obtained and then the \"loss\" or \"error\" for a given observation is ascertained by looking at what the network predicted for that observation and comparing it to what it *should* have predicted. \n",
        "\n",
        "The error for a given observation is calculated by taking the square of the difference between the predicted value and the actual value. \n",
        "\n",
        "We can summarize the overall quality of a network's predictions by finding the average error across all observations. This gives us the \"Mean Squared Error.\" which hopefully is a fairly familiar model evaluation metric by now. Graphing the MSE over each epoch (training cycle) is a common practice with Neural Networks. This is what you're seeing in the top right corner of the Tensorflow Playground website as the number of \"epochs\" climbs higher and higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm43UvfjRyNi",
        "colab_type": "text"
      },
      "source": [
        "## What is an \"Epoch\"?\n",
        "\n",
        "\n",
        "---------- TAKES 1 STEP IN GRADIENT DESENT ----\n",
        "------- EVERYTIME YOU PASS DATA THROUGH THE GRADIENT DECENT IS AN EPOCH\n",
        "\n",
        "An \"Epoch\" is one cycle of passing our data forward through the network, measuring error given our specified cost function, and then -via gradient descent- updating weights within our network to hopefully improve the quality of our predictions on the next iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JFZMtMVRyNw",
        "colab_type": "text"
      },
      "source": [
        "### A note about Hyperparameters\n",
        "\n",
        "Neural Networks have many more hyperparameters than other machine learning algorithms which is part of what makes them a beast to train.\n",
        "\n",
        "1. You need more data to train them on. \n",
        "2. They're complex so they take longer to train. \n",
        "3. They have lots and lots of hyperparameters which we need to find the most optimal combination of, so we might end up training our model dozens or hundreds of times with different combinations of hyperparameters in order to try and squeeze out a few more tenths of a percent of accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aM4CK1IarId4",
        "toc-hr-collapsed": false
      },
      "source": [
        "# Backpropagation (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "toc-hr-collapsed": true,
        "id": "Kf4Ebxl1RyOE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Backpropagation is short for [\"Backwards Propagation of errors\"](https://en.wikipedia.org/wiki/Backpropagation) and refers to a specific (rather calculus intensive) algorithm for how weights in a neural network are updated in reverse order at the end of each training epoch. Our purpose today is to demonstrate the backpropagation algorithm on a simple Feedforward Neural Network and in so doing help you get a grasp on the main process. If you want to understand all of the underlying calculus of how the gradients are calculated then you'll need to dive into it yourself, [3Blue1Brown's video is a great starting place](https://www.youtube.com/watch?v=tIeHLnjs5U8). I also highly recommend this Welch Labs series [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) if you want a rapid yet orderly walk through of the main intuitions and math behind the backpropagation algorithm. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfmnEpmORyOG",
        "colab_type": "text"
      },
      "source": [
        "### What is a Gradient?\n",
        "\n",
        "* GRANDENT DECENT IS LIKE BEING IN A VELLEY IN HEAVY FOG\n",
        "  * TRYING TO FIND YOUR FREIND WHO IS AT THE LOWEST POINT IN THE VALLEY\n",
        "  * EACH STEP IS DONE EACH TIME YOU RUN THE NN. \n",
        "\n",
        "-------------------------------------------------------------------------------\n",
        "> In vector calculus, the gradient is a multi-variable generalization of the derivative. \n",
        "\n",
        "The gradients that we will deal with today will be vector representations of the derivative of the activation function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "3wKJgPslRyOO",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "In this section, we will again implement a multi-layer perceptron using numpy. We'll focus on using a __Feed Forward Neural Network__ to predict test scores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dm2HPETcrgy6",
        "toc-hr-collapsed": true
      },
      "source": [
        "![231 Neural Network](https://cdn-images-1.medium.com/max/1600/1*IjY3wFF24sK9UhiOlf36Bw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4d4tzpwO6B47"
      },
      "source": [
        "### Generate some Fake Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ERyVgeO_IWyV",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(812)\n",
        "\n",
        "# Imagine that our data is drawn from a linear function\n",
        "# y = 2*hours_studying + 4*hours_sleeping + 50\n",
        "\n",
        "# hours studying, hours sleep\n",
        "X = np.array(([2,9],\n",
        "              [1,5],\n",
        "              [3,6]), dtype=float)\n",
        "\n",
        "# Exam Scores\n",
        "y = np.array(([90],\n",
        "              [72],\n",
        "              [80]), dtype=float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOuwRtDpRyOp",
        "colab_type": "text"
      },
      "source": [
        "### Feature Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cDeUBW6k4Ri4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ce46c5ae-2645-4cd7-b50f-e26eb5a6c8f6"
      },
      "source": [
        "# Normalizing Data on feature \n",
        "# Neural Network would probably do this on its own, but it will help us converge on a solution faster\n",
        "X = X / np.amax(X, axis=0) \n",
        "y = y / 100 # devide by the maxium\n",
        "\n",
        "print(\"Studying, Sleeping \\n\", X)\n",
        "print(\"Test Score \\n\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Studying, Sleeping \n",
            " [[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Test Score \n",
            " [[0.9 ]\n",
            " [0.72]\n",
            " [0.8 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bgTf6vTS69Sw"
      },
      "source": [
        "### Neural Network Architecture\n",
        "Lets create a Neural_Network class to contain this functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RUI8VSR5zyBv",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Set up Arch\n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 3\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # Initialize Weights\n",
        "        # 2x3\n",
        "        self.weights1 = np.random.randn(self.inputs,self.hiddenNodes)\n",
        "        \n",
        "        # 3x1\n",
        "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gbyT_FJ88IlK"
      },
      "source": [
        "### Randomly Initialize Weights\n",
        "How many random weights do we need to initialize? \"Fully-connected Layers\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IreIDe6P8H0H",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rip0lQ-QRyPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5911b0dd-72aa-4e5b-fea4-86a9a883d7f2"
      },
      "source": [
        "print(\"Layer 1 weights: \\n\", nn.weights1)\n",
        "print(\"Layer 2 weights: \\n\", nn.weights2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1 weights: \n",
            " [[ 2.48783189  0.11697987 -1.97118428]\n",
            " [-0.48325593 -1.50361209  0.57515126]]\n",
            "Layer 2 weights: \n",
            " [[-0.20672583]\n",
            " [ 0.41271104]\n",
            " [-0.57757999]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hbxDhyjQ-RwS"
      },
      "source": [
        "### Implement Feedforward Functionality\n",
        "\n",
        "After this step our neural network should be able to generate an output even though it has not been trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0gGivpEk-VdP",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Set up Arch\n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 3\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # Initialize Weights\n",
        "        # 2x3\n",
        "        # Input to Hidden (1st set of weights)\n",
        "        self.weights1 = np.random.randn(self.inputs,self.hiddenNodes)\n",
        "        \n",
        "        # 3x1\n",
        "        # Hidden to Output (2nd set of weights)\n",
        "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1+np.exp(-s))\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        Calculate the NN inference using feed forward.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Weighted Sum\n",
        "        self.hidden_sum = np.dot(X, self.weights1) # matrix that are multplieD\n",
        "        \n",
        "        # Activate\n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        # Weighted sum of activated hidden (which output layer will use)\n",
        "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "        \n",
        "        # Final Activation of Output (My Predictions)\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOJMGhjsRyQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1a2745ab-f9fe-478a-8dae-d22e72b302c7"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66666667, 1.        ],\n",
              "       [0.33333333, 0.55555556],\n",
              "       [1.        , 0.66666667]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a1pxdfmDAaJg"
      },
      "source": [
        "### Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpKbuSrsRyQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "45a4bf41-969e-40cd-86bb-7785586b991f"
      },
      "source": [
        "# Try to make a prediction with our updated 'net\n",
        "nn = NeuralNetwork()\n",
        "print(X[0])\n",
        "output = nn.feed_forward(X[0])\n",
        "print(\"output\", output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.66666667 1.        ]\n",
            "output [0.25814933]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3V61yNmAB2T5"
      },
      "source": [
        "### Calculate Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoShUEBqRyQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0224ef8-a5af-49cb-e8ba-df08b539dbb7"
      },
      "source": [
        "error = y[0] - output\n",
        "error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.64185067])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krmutuw7RyQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "5c209873-a96d-4c2b-8886-69b3273898af"
      },
      "source": [
        "output_all = nn.feed_forward(X)\n",
        "error_all = y - output_all\n",
        "print(output_all)\n",
        "print(error_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.25814933]\n",
            " [0.33067192]\n",
            " [0.22642076]]\n",
            "[[0.64185067]\n",
            " [0.38932808]\n",
            " [0.57357924]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "26wgCLU0TLvy"
      },
      "source": [
        "Why is my error so big?\n",
        "\n",
        "My error is so big because my prediction is low.\n",
        "\n",
        "Why are my prediction low?\n",
        "\n",
        "Because either:\n",
        "\n",
        "  1) Second layer **weights** are low\n",
        "  \n",
        "  (or)\n",
        "  \n",
        "  2) Activations coming from the first layer are low\n",
        "  \n",
        "How are activations from the first layer determined? \n",
        "\n",
        "  1) By inputs - fixed\n",
        "  \n",
        "  2) by **weights** - variable\n",
        "  \n",
        "The only thing that I have control over throughout this process in order to increase the value of my final predictions is to either increase weights in layer 2 or increase weights in layer 1. \n",
        "\n",
        "Imagine that you could only change your weights by a fixed amount. Say you have .3 and you have to split that up and disperse it over your weights so as to increase your predictions as much as possible. (This isn't actually what happens, but it will help us identify which weights we would benefit the most from moving.)\n",
        "\n",
        "I need to increase weights of my model somewhere, I'll get the biggest bang for my buck if I increase weights in places where I'm already seeing high activation values -because they end up getting multiplied together before being passed to the sigmoid function. \n",
        "\n",
        "> \"Neurons that fire together, wire together\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j_eyzItYIxgm"
      },
      "source": [
        "### Implement Backpropagation \n",
        "\n",
        "> *Assigning blame for bad predictions and delivering justice - repeatedly and a little bit at a time*\n",
        "\n",
        "What in our model could be causing our predictions to suck so bad? \n",
        "\n",
        "Well, we know that our inputs (X) and outputs (y) are correct, if they weren't then we would have bigger problems than understanding backpropagation.\n",
        "\n",
        "We also know that our activation function (sigmoid) is working correctly. It can't be blamed because it just does whatever we tell it to and transforms the data in a known way.\n",
        "\n",
        "So what are the potential culprits for these terrible predictions? The **weights** of our model. Here's the problem though. I have weights that exist in both layers of my model. How do I know if the weights in the first layer are to blame, or the second layer, or both? \n",
        "\n",
        "Lets investigate. And see if we can just eyeball what should be updated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CwOeJAlRyQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "d826c821-1dd9-4a37-97b5-7e5b4617d2d2"
      },
      "source": [
        "attributes = ['weights1', 'hidden_sum', 'activated_hidden', 'weights2', 'activated_output']\n",
        "[print(i+'\\n', getattr(nn,i), '\\n'+'---'*3) for i in attributes if i[:2]!= '__'] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights1\n",
            " [[-1.75351135  1.23279898  0.24464757]\n",
            " [-0.06568225  0.30190098  0.79723428]] \n",
            "---------\n",
            "hidden_sum\n",
            " [[-1.23468981  1.12376697  0.96033266]\n",
            " [-0.62099392  0.57865576  0.52445712]\n",
            " [-1.79729952  1.4340663   0.77613709]] \n",
            "---------\n",
            "activated_hidden\n",
            " [[0.22536165 0.75468678 0.7231884 ]\n",
            " [0.34955543 0.64075804 0.6281894 ]\n",
            " [0.14218011 0.8075341  0.68484697]] \n",
            "---------\n",
            "weights2\n",
            " [[ 1.23073545]\n",
            " [-1.52187331]\n",
            " [-0.25502715]] \n",
            "---------\n",
            "activated_output\n",
            " [[0.25814933]\n",
            " [0.33067192]\n",
            " [0.22642076]] \n",
            "---------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "16Ujj6vNYQyX",
        "toc-hr-collapsed": true
      },
      "source": [
        "### Update Weights Based on Gradient\n",
        "\n",
        "Repeat steps 2-4 for every observation in a given batch, and then given the network's cost function, calculate its gradient using calculus and update weights associated with the (negative) gradient of the cost function. \n",
        "\n",
        "Remember that we have 9 weights in our network therefore the gradient that comes from our gradient descent calculation will be the vector that takes us in the most downward direction along some function in 9-dimensional hyperspace. <br>\n",
        "-------- these below are all the weights ------------\n",
        "\\begin{align}\n",
        "C(w1, w2, w3, w4, w5, w6, w7, w8, w9)\n",
        "\\end{align}\n",
        "\n",
        "You should also know that with neural networks it is common to have gradients that are not convex (like what we saw when we applied gradient descent to linear regression). Due to the high complexity of these models and their nonlinearity, it is common for gradient descent to get stuck in a local minimum, but there are ways to combat this:\n",
        "\n",
        "1) Stochastic Gradient Descent\n",
        "\n",
        "2) More advanced Gradient-Descent-based \"Optimizers\" - See Stretch Goals on assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xmXBtlXRyRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I want activations that correspond to negative weights to be lower\n",
        "# and activations that correspond to positive weights to be higher\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Set up Arch\n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 3\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # Initialize Weights\n",
        "        # 2x3\n",
        "        # Input to Hidden (1st set of weights)\n",
        "        self.weights1 = np.random.randn(self.inputs,self.hiddenNodes)\n",
        "        \n",
        "        # 3x1\n",
        "        # Hidden to Output (2nd set of weights)\n",
        "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1+np.exp(-s))\n",
        "    \n",
        "    def sigmoidPrime(self, s):\n",
        "        sx = self.sigmoid(s)\n",
        "        return sx * (1-sx)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        Calculate the NN inference using feed forward.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Weighted Sum\n",
        "        self.hidden_sum = np.dot(X, self.weights1)\n",
        "        \n",
        "        # Activate\n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        # Weighted sum of activated hidden (which output layer will use)\n",
        "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "        \n",
        "        # Final Activation of Output (My Predictions)\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output\n",
        "    \n",
        "    def backward(self, X, y, o):\n",
        "        \"\"\"\n",
        "        Back prop thru the network - helps adjust weights layers prior\n",
        "        \"\"\"\n",
        "        \n",
        "        self.o_error = y - o # Error in the output\n",
        "        \n",
        "        # Apply derivative of sigmoid to error\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "        \n",
        "        # z2 error: how much were our output layer weights off\n",
        "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
        "        \n",
        "        # z2 delta: how much were the weights off?\n",
        "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.output_sum)\n",
        "\n",
        "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
        "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
        "        \n",
        "    def train(self, X,y):\n",
        "        o = self.feed_forward(X)\n",
        "        self.backward(X,y,o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "Hq2dGX-HRyRU",
        "colab_type": "text"
      },
      "source": [
        "#### Let's look at the shape of the Gradient Componets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPqJdSZvRyRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "nn.train(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im4e5wOYRyRh",
        "colab_type": "text"
      },
      "source": [
        "##### Our Error Associated with Each Observation \n",
        "aka how wrong were we?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jREpmvfyRyRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a828e25c-e48e-4a9c-f53c-db690a401fbe"
      },
      "source": [
        "nn.o_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60746115],\n",
              "       [0.46613403],\n",
              "       [0.53667427]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxmpxmeHRyRu",
        "colab_type": "text"
      },
      "source": [
        "##### 1st Gradient \n",
        "Simple interpretation - how much more sigmoid activation would have pushed us towards the right answer?\n",
        "\n",
        "`self.o_delta = self.o_error * self.sigmoidPrime(self.output_sum)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8E31gQ6RyRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ad421f97-8df0-48bc-a07a-4ed4f88b715a"
      },
      "source": [
        "nn.o_delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14866196],\n",
              "       [0.11467591],\n",
              "       [0.13186936]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06oPDg-WRyR5",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the derivate of the sigmoid function to understand what's happening. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XobISyucRyR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "line_x = np.arange(-5, 5, 0.01)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1+ np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1-sx)\n",
        "\n",
        "# sigmoid\n",
        "y = sigmoid(line_x)\n",
        "y_d = sigmoid_derivative(line_x)\n",
        "\n",
        "x = nn.output_sum\n",
        "s = sigmoid(x)\n",
        "sx = sigmoid_derivative(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRp-qd-zRySC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "31619640-6e19-4e4c-c258-e4962013f821"
      },
      "source": [
        "# call regplot on each axes\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(15,5))\n",
        "sns.lineplot(x=line_x, y=y, ax=ax1)\n",
        "ax1.plot(x[0], s[0], 'ro')\n",
        "ax1.set_title(\"Sigmoid of Weighted Sum\")\n",
        "sns.lineplot(x=line_x, y=y_d, ax=ax2) \n",
        "ax2.plot(x[0],sx[0],'ro');\n",
        "ax2.set_title(\"Sigmoid Derivative of Weighted Sum\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v61DaNMCRySO",
        "colab_type": "text"
      },
      "source": [
        "Look at the derivate graph. The derivative multiplied by the error tells us where to assign blame and update the weights most effective. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuJoU2jhRySQ",
        "colab_type": "text"
      },
      "source": [
        "##### 2nd Error\n",
        "Justice hasn't been served yet - tho. We still have neurons to blame. Let's go back another layer. \n",
        "\n",
        "`self.z2_error = self.o_delta.dot(self.weights2.T)`\n",
        "\n",
        "__Discussion:__ Why is this shape different?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVYjO9dRySR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "85c131f9-2d97-4800-c9f7-3888f3e4c270"
      },
      "source": [
        "nn.o_delta.dot(nn.weights2.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.23952061, -0.19347426,  0.1111231 ],\n",
              "       [-0.1847631 , -0.14924354,  0.08571892],\n",
              "       [-0.21246478, -0.17161974,  0.09857082]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bExb7nZdRySY",
        "colab_type": "text"
      },
      "source": [
        "##### 2nd Gradient\n",
        "For each observation, how much more sigmoid activation from this layer would have pushed us towards the right answer?\n",
        "\n",
        "`self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ87QHHBRySa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8e5443fd-11da-435e-882c-53a3984d4093"
      },
      "source": [
        "nn.z2_delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05483346, -0.04408088,  0.01744341],\n",
              "       [-0.03871267, -0.0311213 ,  0.01231513],\n",
              "       [-0.04559029, -0.03665025,  0.01450301]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHgRZtRSRySe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76150b38-3e24-4dc3-84bf-8e078228e823"
      },
      "source": [
        "X.T.shape == nn.weights1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3sy-WcORySn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCl6uOcgRySs",
        "colab_type": "text"
      },
      "source": [
        "##### Descent\n",
        "\n",
        "*Discussion:* Input to Hidden Weight Update\n",
        "- We multiply the gradient by the inputs. Why?\n",
        "- Why do we need to transpose the inputs? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFg1Nd7fRySt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b86d559c-220b-4d6f-cc81-2c0f1ea1f401"
      },
      "source": [
        "X.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66666667, 0.33333333, 1.        ],\n",
              "       [1.        , 0.55555556, 0.66666667]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTzOMO4eRySz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d3680c5f-f13e-49de-cec4-ee9dd8b90bdf"
      },
      "source": [
        "X.T.dot(nn.z2_delta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.09505015, -0.07641127,  0.03023699],\n",
              "       [-0.10673402, -0.08580399,  0.03395382]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHAE5Fa4RyS4",
        "colab_type": "text"
      },
      "source": [
        "*Discussion:* Hidden to Output Weight Update\n",
        "- Why is output the shape 3x1? \n",
        "- We multiply the gradient by the inputs. Why?\n",
        "- Why do we need to transpose the inputs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEtN22x9RyS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f4b09a4f-09bf-4e03-b6bc-a119df95f4c1"
      },
      "source": [
        "nn.activated_hidden.T.dot(nn.o_delta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17103686],\n",
              "       [0.13129211],\n",
              "       [0.18053762]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2orT1i7RyS9",
        "colab_type": "text"
      },
      "source": [
        "### Train the Network (fo real this time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chNCdRR5RyS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bad4d6f3-55ec-41da-f85d-40b8dcd4264c"
      },
      "source": [
        "# Train my 'net\n",
        "nn = NeuralNetwork()\n",
        "\n",
        "# Number of Epochs / Iterations\n",
        "for i in range(5000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 500 ==0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        print('Input: \\n', X)\n",
        "        print('Actual Output: \\n', y)\n",
        "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------EPOCH 1---------+\n",
            "Input: \n",
            " [[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            " [0.00669285 0.00675966 0.00682713 0.00689527 0.00696409 0.00703359\n",
            " 0.00710377 0.00717466 0.00724624 0.00731853 0.00739154 0.00746527\n",
            " 0.00753973 0.00761493 0.00769088 0.00776757 0.00784502 0.00792324\n",
            " 0.00800223 0.00808201 0.00816257 0.00824393 0.00832609 0.00840907\n",
            " 0.00849286 0.00857749 0.00866294 0.00874925 0.0088364  0.00892442\n",
            " 0.0090133  0.00910306 0.00919371 0.00928525 0.00937769 0.00947104\n",
            " 0.00956532 0.00966052 0.00975667 0.00985376 0.0099518  0.01005081\n",
            " 0.0101508  0.01025177 0.01035374 0.01045671 0.01056069 0.01066569\n",
            " 0.01077173 0.01087881 0.01098694 0.01109614 0.01120641 0.01131776\n",
            " 0.0114302  0.01154375 0.01165842 0.01177421 0.01189113 0.0120092\n",
            " 0.01212843 0.01224883 0.01237041 0.01249319 0.01261716 0.01274235\n",
            " 0.01286876 0.01299642 0.01312532 0.01325548 0.01338692 0.01351964\n",
            " 0.01365366 0.01378899 0.01392564 0.01406363 0.01420296 0.01434366\n",
            " 0.01448572 0.01462918 0.01477403 0.0149203  0.01506799 0.01521712\n",
            " 0.01536771 0.01551976 0.01567329 0.01582831 0.01598485 0.01614291\n",
            " 0.0163025  0.01646364 0.01662636 0.01679065 0.01695654 0.01712403\n",
            " 0.01729316 0.01746392 0.01763634 0.01781043 0.01798621 0.01816369\n",
            " 0.01834289 0.01852382 0.01870651 0.01889096 0.0190772  0.01926523\n",
            " 0.01945508 0.01964677 0.01984031 0.02003571 0.020233   0.02043219\n",
            " 0.0206333  0.02083634 0.02104135 0.02124832 0.02145729 0.02166827\n",
            " 0.02188127 0.02209632 0.02231344 0.02253264 0.02275394 0.02297737\n",
            " 0.02320294 0.02343067 0.02366058 0.02389269 0.02412702 0.02436359\n",
            " 0.02460243 0.02484354 0.02508696 0.0253327  0.02558079 0.02583124\n",
            " 0.02608408 0.02633932 0.02659699 0.02685712 0.02711972 0.02738481\n",
            " 0.02765242 0.02792257 0.02819529 0.02847059 0.0287485  0.02902904\n",
            " 0.02931223 0.0295981  0.02988668 0.03017798 0.03047203 0.03076886\n",
            " 0.03106848 0.03137093 0.03167623 0.0319844  0.03229546 0.03260946\n",
            " 0.03292639 0.03324631 0.03356922 0.03389516 0.03422416 0.03455623\n",
            " 0.03489141 0.03522972 0.03557119 0.03591585 0.03626372 0.03661483\n",
            " 0.03696921 0.03732689 0.03768789 0.03805225 0.03841999 0.03879113\n",
            " 0.03916572 0.03954378 0.03992533 0.04031042 0.04069905 0.04109128\n",
            " 0.04148712 0.04188661 0.04228977 0.04269664 0.04310725 0.04352163\n",
            " 0.04393982 0.04436183 0.0447877  0.04521747 0.04565117 0.04608883\n",
            " 0.04653047 0.04697615 0.04742587 0.04787969 0.04833763 0.04879972\n",
            " 0.04926601 0.04973651 0.05021127 0.05069032 0.0511737  0.05166144\n",
            " 0.05215356 0.05265012 0.05315114 0.05365665 0.0541667  0.05468132\n",
            " 0.05520054 0.0557244  0.05625293 0.05678618 0.05732418 0.05786696\n",
            " 0.05841456 0.05896701 0.05952437 0.06008665 0.0606539  0.06122616\n",
            " 0.06180347 0.06238585 0.06297336 0.06356602 0.06416388 0.06476697\n",
            " 0.06537533 0.06598901 0.06660804 0.06723245 0.06786229 0.0684976\n",
            " 0.06913842 0.06978478 0.07043673 0.0710943  0.07175754 0.07242649\n",
            " 0.07310117 0.07378165 0.07446795 0.07516011 0.07585818 0.0765622\n",
            " 0.0772722  0.07798824 0.07871034 0.07943855 0.08017291 0.08091347\n",
            " 0.08166026 0.08241332 0.0831727  0.08393843 0.08471057 0.08548914\n",
            " 0.08627419 0.08706577 0.08786391 0.08866866 0.08948006 0.09029814\n",
            " 0.09112296 0.09195455 0.09279295 0.09363821 0.09449037 0.09534946\n",
            " 0.09621554 0.09708864 0.0979688  0.09885607 0.09975049 0.10065209\n",
            " 0.10156093 0.10247703 0.10340045 0.10433122 0.10526939 0.10621499\n",
            " 0.10716807 0.10812867 0.10909682 0.11007257 0.11105597 0.11204704\n",
            " 0.11304583 0.11405238 0.11506673 0.11608892 0.11711899 0.11815698\n",
            " 0.11920292 0.12025686 0.12131884 0.12238889 0.12346705 0.12455336\n",
            " 0.12564786 0.12675058 0.12786157 0.12898085 0.13010847 0.13124447\n",
            " 0.13238887 0.13354172 0.13470305 0.1358729  0.13705129 0.13823827\n",
            " 0.13943387 0.14063813 0.14185106 0.14307272 0.14430313 0.14554233\n",
            " 0.14679034 0.1480472  0.14931293 0.15058758 0.15187116 0.15316372\n",
            " 0.15446527 0.15577584 0.15709547 0.15842418 0.159762   0.16110895\n",
            " 0.16246506 0.16383036 0.16520487 0.16658861 0.16798161 0.1693839\n",
            " 0.17079548 0.17221639 0.17364665 0.17508627 0.17653527 0.17799369\n",
            " 0.17946152 0.18093879 0.18242552 0.18392173 0.18542742 0.18694261\n",
            " 0.18846733 0.19000157 0.19154535 0.19309868 0.19466158 0.19623406\n",
            " 0.19781611 0.19940776 0.201009   0.20261985 0.2042403  0.20587037\n",
            " 0.20751006 0.20915937 0.21081829 0.21248684 0.21416502 0.21585281\n",
            " 0.21755022 0.21925725 0.22097389 0.22270014 0.22443599 0.22618143\n",
            " 0.22793645 0.22970105 0.23147522 0.23325894 0.2350522  0.23685498\n",
            " 0.23866729 0.24048908 0.24232036 0.2441611  0.24601128 0.24787089\n",
            " 0.24973989 0.25161828 0.25350602 0.25540308 0.25730945 0.2592251\n",
            " 0.26114999 0.2630841  0.2650274  0.26697985 0.26894142 0.27091208\n",
            " 0.27289178 0.2748805  0.27687819 0.27888482 0.28090034 0.28292471\n",
            " 0.28495789 0.28699984 0.2890505  0.29110983 0.29317778 0.2952543\n",
            " 0.29733935 0.29943286 0.30153478 0.30364507 0.30576366 0.3078905\n",
            " 0.31002552 0.31216867 0.31431989 0.31647911 0.31864627 0.3208213\n",
            " 0.32300414 0.32519473 0.32739298 0.32959884 0.33181223 0.33403307\n",
            " 0.3362613  0.33849684 0.34073961 0.34298954 0.34524654 0.34751054\n",
            " 0.34978145 0.3520592  0.35434369 0.35663485 0.35893259 0.36123682\n",
            " 0.36354746 0.36586441 0.36818758 0.37051689 0.37285223 0.37519353\n",
            " 0.37754067 0.37989357 0.38225213 0.38461624 0.38698582 0.38936077\n",
            " 0.39174097 0.39412633 0.39651675 0.39891212 0.40131234 0.4037173\n",
            " 0.4061269  0.40854102 0.41095957 0.41338242 0.41580948 0.41824062\n",
            " 0.42067575 0.42311474 0.42555748 0.42800387 0.43045378 0.4329071\n",
            " 0.43536371 0.4378235  0.44028635 0.44275215 0.44522076 0.44769209\n",
            " 0.450166   0.45264238 0.45512111 0.45760206 0.46008512 0.46257015\n",
            " 0.46505705 0.46754569 0.47003595 0.4725277  0.47502081 0.47751518\n",
            " 0.48001066 0.48250714 0.4850045  0.4875026  0.49000133 0.49250056\n",
            " 0.49500017 0.49750002 0.5        0.50249998 0.50499983 0.50749944\n",
            " 0.50999867 0.5124974  0.5149955  0.51749286 0.51998934 0.52248482\n",
            " 0.52497919 0.5274723  0.52996405 0.53245431 0.53494295 0.53742985\n",
            " 0.53991488 0.54239794 0.54487889 0.54735762 0.549834   0.55230791\n",
            " 0.55477924 0.55724785 0.55971365 0.5621765  0.56463629 0.5670929\n",
            " 0.56954622 0.57199613 0.57444252 0.57688526 0.57932425 0.58175938\n",
            " 0.58419052 0.58661758 0.58904043 0.59145898 0.5938731  0.5962827\n",
            " 0.59868766 0.60108788 0.60348325 0.60587367 0.60825903 0.61063923\n",
            " 0.61301418 0.61538376 0.61774787 0.62010643 0.62245933 0.62480647\n",
            " 0.62714777 0.62948311 0.63181242 0.63413559 0.63645254 0.63876318\n",
            " 0.64106741 0.64336515 0.64565631 0.6479408  0.65021855 0.65248946\n",
            " 0.65475346 0.65701046 0.65926039 0.66150316 0.6637387  0.66596693\n",
            " 0.66818777 0.67040116 0.67260702 0.67480527 0.67699586 0.6791787\n",
            " 0.68135373 0.68352089 0.68568011 0.68783133 0.68997448 0.6921095\n",
            " 0.69423634 0.69635493 0.69846522 0.70056714 0.70266065 0.7047457\n",
            " 0.70682222 0.70889017 0.7109495  0.71300016 0.71504211 0.71707529\n",
            " 0.71909966 0.72111518 0.72312181 0.7251195  0.72710822 0.72908792\n",
            " 0.73105858 0.73302015 0.7349726  0.7369159  0.73885001 0.7407749\n",
            " 0.74269055 0.74459692 0.74649398 0.74838172 0.75026011 0.75212911\n",
            " 0.75398872 0.7558389  0.75767964 0.75951092 0.76133271 0.76314502\n",
            " 0.7649478  0.76674106 0.76852478 0.77029895 0.77206355 0.77381857\n",
            " 0.77556401 0.77729986 0.77902611 0.78074275 0.78244978 0.78414719\n",
            " 0.78583498 0.78751316 0.78918171 0.79084063 0.79248994 0.79412963\n",
            " 0.7957597  0.79738015 0.798991   0.80059224 0.80218389 0.80376594\n",
            " 0.80533842 0.80690132 0.80845465 0.80999843 0.81153267 0.81305739\n",
            " 0.81457258 0.81607827 0.81757448 0.81906121 0.82053848 0.82200631\n",
            " 0.82346473 0.82491373 0.82635335 0.82778361 0.82920452 0.8306161\n",
            " 0.83201839 0.83341139 0.83479513 0.83616964 0.83753494 0.83889105\n",
            " 0.840238   0.84157582 0.84290453 0.84422416 0.84553473 0.84683628\n",
            " 0.84812884 0.84941242 0.85068707 0.8519528  0.85320966 0.85445767\n",
            " 0.85569687 0.85692728 0.85814894 0.85936187 0.86056613 0.86176173\n",
            " 0.86294871 0.8641271  0.86529695 0.86645828 0.86761113 0.86875553\n",
            " 0.86989153 0.87101915 0.87213843 0.87324942 0.87435214 0.87544664\n",
            " 0.87653295 0.87761111 0.87868116 0.87974314 0.88079708 0.88184302\n",
            " 0.88288101 0.88391108 0.88493327 0.88594762 0.88695417 0.88795296\n",
            " 0.88894403 0.88992743 0.89090318 0.89187133 0.89283193 0.89378501\n",
            " 0.89473061 0.89566878 0.89659955 0.89752297 0.89843907 0.89934791\n",
            " 0.90024951 0.90114393 0.9020312  0.90291136 0.90378446 0.90465054\n",
            " 0.90550963 0.90636179 0.90720705 0.90804545 0.90887704 0.90970186\n",
            " 0.91051994 0.91133134 0.91213609 0.91293423 0.91372581 0.91451086\n",
            " 0.91528943 0.91606157 0.9168273  0.91758668 0.91833974 0.91908653\n",
            " 0.91982709 0.92056145 0.92128966 0.92201176 0.9227278  0.9234378\n",
            " 0.92414182 0.92483989 0.92553205 0.92621835 0.92689883 0.92757351\n",
            " 0.92824246 0.9289057  0.92956327 0.93021522 0.93086158 0.9315024\n",
            " 0.93213771 0.93276755 0.93339196 0.93401099 0.93462467 0.93523303\n",
            " 0.93583612 0.93643398 0.93702664 0.93761415 0.93819653 0.93877384\n",
            " 0.9393461  0.93991335 0.94047563 0.94103299 0.94158544 0.94213304\n",
            " 0.94267582 0.94321382 0.94374707 0.9442756  0.94479946 0.94531868\n",
            " 0.9458333  0.94634335 0.94684886 0.94734988 0.94784644 0.94833856\n",
            " 0.9488263  0.94930968 0.94978873 0.95026349 0.95073399 0.95120028\n",
            " 0.95166237 0.95212031 0.95257413 0.95302385 0.95346953 0.95391117\n",
            " 0.95434883 0.95478253 0.9552123  0.95563817 0.95606018 0.95647837\n",
            " 0.95689275 0.95730336 0.95771023 0.95811339 0.95851288 0.95890872\n",
            " 0.95930095 0.95968958 0.96007467 0.96045622 0.96083428 0.96120887\n",
            " 0.96158001 0.96194775 0.96231211 0.96267311 0.96303079 0.96338517\n",
            " 0.96373628 0.96408415 0.96442881 0.96477028 0.96510859 0.96544377\n",
            " 0.96577584 0.96610484 0.96643078 0.96675369 0.96707361 0.96739054\n",
            " 0.96770454 0.9680156  0.96832377 0.96862907 0.96893152 0.96923114\n",
            " 0.96952797 0.96982202 0.97011332 0.9704019  0.97068777 0.97097096\n",
            " 0.9712515  0.97152941 0.97180471 0.97207743 0.97234758 0.97261519\n",
            " 0.97288028 0.97314288 0.97340301 0.97366068 0.97391592 0.97416876\n",
            " 0.97441921 0.9746673  0.97491304 0.97515646 0.97539757 0.97563641\n",
            " 0.97587298 0.97610731 0.97633942 0.97656933 0.97679706 0.97702263\n",
            " 0.97724606 0.97746736 0.97768656 0.97790368 0.97811873 0.97833173\n",
            " 0.97854271 0.97875168 0.97895865 0.97916366 0.9793667  0.97956781\n",
            " 0.979767   0.97996429 0.98015969 0.98035323 0.98054492 0.98073477\n",
            " 0.9809228  0.98110904 0.98129349 0.98147618 0.98165711 0.98183631\n",
            " 0.98201379 0.98218957 0.98236366 0.98253608 0.98270684 0.98287597\n",
            " 0.98304346 0.98320935 0.98337364 0.98353636 0.9836975  0.98385709\n",
            " 0.98401515 0.98417169 0.98432671 0.98448024 0.98463229 0.98478288\n",
            " 0.98493201 0.9850797  0.98522597 0.98537082 0.98551428 0.98565634\n",
            " 0.98579704 0.98593637 0.98607436 0.98621101 0.98634634 0.98648036\n",
            " 0.98661308 0.98674452 0.98687468 0.98700358 0.98713124 0.98725765\n",
            " 0.98738284 0.98750681 0.98762959 0.98775117 0.98787157 0.9879908\n",
            " 0.98810887 0.98822579 0.98834158 0.98845625 0.9885698  0.98868224\n",
            " 0.98879359 0.98890386 0.98901306 0.98912119 0.98922827 0.98933431\n",
            " 0.98943931 0.98954329 0.98964626 0.98974823 0.9898492  0.98994919\n",
            " 0.9900482  0.99014624 0.99024333 0.99033948 0.99043468 0.99052896\n",
            " 0.99062231 0.99071475 0.99080629 0.99089694 0.9909867  0.99107558\n",
            " 0.9911636  0.99125075 0.99133706 0.99142251 0.99150714 0.99159093\n",
            " 0.99167391 0.99175607 0.99183743 0.99191799 0.99199777 0.99207676\n",
            " 0.99215498 0.99223243 0.99230912 0.99238507 0.99246027 0.99253473\n",
            " 0.99260846 0.99268147 0.99275376 0.99282534 0.99289623 0.99296641\n",
            " 0.99303591 0.99310473 0.99317287 0.99324034]\n",
            "Predicted Output: \n",
            " [[0.37771334]\n",
            " [0.41477855]\n",
            " [0.40348484]]\n",
            "Loss: \n",
            " 0.16174922917818682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c7a311b64a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Output: \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-caf01bb1d477>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-caf01bb1d477>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y, o)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# z2 error: how much were our output layer weights off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# z2 delta: how much were the weights off?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (3,1000) and (1,3) not aligned: 1000 (dim 1) != 1 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ddubClIRyTC",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "In the module project, you will implement backpropagation inside a multi-layer perceptron (aka a feedforward neural network). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "L4NqffVCRyTD",
        "colab_type": "text"
      },
      "source": [
        "# Stochastic Gradient Descent (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PacU7a6JRyTE",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The What - Stochastic Gradient Descent calculates an approximation of the gradient over the entire dataset by reviewing the predictions of a random sample. \n",
        "\n",
        "The Why - *Speed*. Calculating the gradient over the entire dataset is extremely expensive computationally. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZF7UE-KluPsX"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "A true Stochastic GD-based implementation from [Welch Labs](https://www.youtube.com/watch?v=bxe2T-V8XRs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTI51M6ZRyTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X,y)\n",
        "model.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wa29WvzRyTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(object):\n",
        "    def __init__(self):        \n",
        "        #Define Hyperparameters\n",
        "        self.inputLayerSize = 2\n",
        "        self.outputLayerSize = 1\n",
        "        self.hiddenLayerSize = 3\n",
        "        \n",
        "        #Weights (parameters)\n",
        "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
        "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        #Propogate inputs though network\n",
        "        self.z2 = np.dot(X, self.W1)\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        self.z3 = np.dot(self.a2, self.W2)\n",
        "        yHat = self.sigmoid(self.z3) \n",
        "        return yHat\n",
        "        \n",
        "    def sigmoid(self, z):\n",
        "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
        "        return 1/(1+np.exp(-z))\n",
        "    \n",
        "    def sigmoidPrime(self,z):\n",
        "        #Gradient of sigmoid\n",
        "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
        "    \n",
        "    def costFunction(self, X, y):\n",
        "        #Compute cost for given X,y, use weights already stored in class.\n",
        "        self.yHat = self.forward(X)\n",
        "        J = 0.5*sum((y-self.yHat)**2)\n",
        "        return J\n",
        "        \n",
        "    def costFunctionPrime(self, X, y):\n",
        "        #Compute derivative with respect to W and W2 for a given X and y:\n",
        "        self.yHat = self.forward(X)\n",
        "        \n",
        "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
        "        dJdW2 = np.dot(self.a2.T, delta3)\n",
        "        \n",
        "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
        "        dJdW1 = np.dot(X.T, delta2)  \n",
        "        \n",
        "        return dJdW1, dJdW2\n",
        "    \n",
        "    #Helper Functions for interacting with other classes:\n",
        "    def getParams(self):\n",
        "        #Get W1 and W2 unrolled into vector:\n",
        "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
        "        return params\n",
        "    \n",
        "    def setParams(self, params):\n",
        "        #Set W1 and W2 using single paramater vector.\n",
        "        W1_start = 0\n",
        "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
        "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
        "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
        "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
        "        \n",
        "    def computeGradients(self, X, y):\n",
        "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
        "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uA9LaTgKr6rP",
        "colab": {}
      },
      "source": [
        "from scipy import optimize\n",
        "class trainer(object):\n",
        "    def __init__(self, N):\n",
        "        #Make Local reference to network:\n",
        "        self.N = N\n",
        "        \n",
        "    def callbackF(self, params):\n",
        "        self.N.setParams(params)\n",
        "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
        "        \n",
        "    def costFunctionWrapper(self, params, X, y):\n",
        "        self.N.setParams(params)\n",
        "        cost = self.N.costFunction(X, y)\n",
        "        grad = self.N.computeGradients(X,y)\n",
        "        \n",
        "        return cost, grad\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        #Make an internal variable for the callback function:\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        #Make empty list to store costs:\n",
        "        self.J = []\n",
        "        \n",
        "        params0 = self.N.getParams()\n",
        "\n",
        "        options = {'maxiter': 200, 'disp' : True}\n",
        "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', display=  \\\n",
        "                                 args=(X, y), options=options, callback=self.callbackF)\n",
        "\n",
        "        self.N.setParams(_res.x)\n",
        "        self.optimizationResults = _res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g_kHb6Se1u9y",
        "colab": {}
      },
      "source": [
        "NN = Neural_Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hYYVhFf4rn3q",
        "colab": {}
      },
      "source": [
        "T = trainer(NN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-gYdVfgrysE",
        "colab": {}
      },
      "source": [
        "T.train(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jyv_L8Z2sKOA",
        "colab": {}
      },
      "source": [
        "print(\"Predicted Output: \\n\" + str(NN.forward(X))) \n",
        "print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.forward(X))))) # mean sum squared loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gtf9WI9FtGPk",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(T.J)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0a_59R4RyTn",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "This is a reference implementation for you to explore. You will not be expected to apply it to today's module project. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ApRIe3qRyTo",
        "colab_type": "text"
      },
      "source": [
        "# Keras Sequential API (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "io_I2Zq5RyTo",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "----most don't use numpy for NN IT'S VERY COSTLY - SO KERAS IS PIOPULAR ---\n",
        "\n",
        "\n",
        "> \"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research. Use Keras if you need a deep learning library that:\n",
        "\n",
        "> Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
        "Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
        "Runs seamlessly on CPU and GPU.\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AIJoRBxHy27n"
      },
      "source": [
        "### Keras Perceptron Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6T4nRy9RyTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')\n",
        "X = df[['x1', 'x2']].values\n",
        "y = df['y'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TQxyONqKvFxB",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# This is our perceptron from Monday's by-hand: \n",
        "model = Sequential()\n",
        "model.add(Dense(1,input_dim=2, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X,y, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z1wfKUxszPKa",
        "colab": {}
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, y)\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "cy2V5kXRRyT0",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "In the `Sequential` api model, you specify a model architecture by 'sequentially specifying layers. This type of specification works well for feed forward neural networks in which the data flows in one direction (forward propagation) and the error flows in the opposite direction (backwards propagation). The Keras `Sequential` API follows a standardarized worklow to estimate a 'net: \n",
        "\n",
        "1. Load Data\n",
        "2. Define Model\n",
        "3. Compile Model\n",
        "4. Fit Model\n",
        "5. Evaluate Model\n",
        "\n",
        "You saw these steps in our Keras Perceptron Sample, but let's walk thru each step in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Md5D67XwqVAf",
        "toc-hr-collapsed": false
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bn09phMBpY1J",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Stretch - use dropout \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOp6jW3zRyT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhB6lf7ORyT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJLWrrgkRyUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31W1WN5URyUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X Variable Types\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') /255.\n",
        "\n",
        "# Correct Encoding on Y\n",
        "# What softmax expects = [0,0,0,0,0,1,0,0,0,0]\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0xMqOyTs5xt"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bp9USczrfu6M",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(812)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wAzHLg27thoN"
      },
      "source": [
        "I'll instantiate my model as a \"sequential\" model. This just means that I'm going to tell Keras what my model's architecture should be one layer at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DSNsL49Xp6KI",
        "colab": {}
      },
      "source": [
        "# https://keras.io/getting-started/sequential-model-guide/\n",
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZCYX6QzJtvpG"
      },
      "source": [
        "Adding a \"Dense\" layer to our model is how we add \"vanilla\" perceptron-based layers to our neural network. These are also called \"fully-connected\" or \"densely-connected\" layers. They're used as a layer type in lots of other Neural Net Architectures but they're not referred to as perceptrons or multi-layer perceptrons very often in those situations even though that's what they are.\n",
        "\n",
        " > [\"Just your regular densely-connected NN layer.\"](https://keras.io/layers/core/)\n",
        " \n",
        " The first argument is how many neurons we want to have in that layer. To create a perceptron-esque model we will just set it to 10. Our architecture is just an input and output layer. We will tell it that there will be 784 inputs coming into this layer from our dataset and set it to use the sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GNzOLidxtvFa",
        "colab": {}
      },
      "source": [
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(10,activation=\"softmax\")) #Relu is valid option. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EnI3jwKMtBL2",
        "toc-hr-collapsed": false
      },
      "source": [
        "### Compile Model\n",
        "Using binary_crossentropy as the loss function here is just telling keras that I'm doing binary classification so that it can use the appropriate loss function accordingly. If we were predicting non-binary categories we might assign something like `categorical_crossentropy`. We're also telling keras that we want it to report model accuracy as our main error metric for each epoch. We will also be able to see the overall accuracy once the model has finished training.\n",
        "\n",
        "#### Adam Optimizer\n",
        "Check out this links for more background on the Adam optimizer and Stohastic Gradient Descent\n",
        "* [Adam Optimization Algorithm](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
        "* [Adam Optimizer - original paper](https://arxiv.org/abs/1412.6980)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qp6xwYaqurRO",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5dW8SZ2Ls9SX",
        "toc-hr-collapsed": false
      },
      "source": [
        "### Fit Model\n",
        "\n",
        "Lets train it up! `model.fit()` has a `batch_size` parameter that we can use if we want to do mini-batch epochs, but since this tabular dataset is pretty small we're just going to delete that parameter. Keras' default `batch_size` is `None` so omiting it will tell Keras to do batch epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeZZyonTRyUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLmGsynvRyUu",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "477ezPLxRyUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(X_test,y_test)\n",
        "print(\"\\n\")\n",
        "print(\"Validation Data Metrics:\")\n",
        "print(f\"{model.metrics_names[0]}: {scores[0]}\")\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zHYB7k9q3O8T"
      },
      "source": [
        "### Unstable Results\n",
        "\n",
        "You'll notice that if we rerun the results might differ from the origin run. This can be explain by a bunch of factors. Check out some of them in this article: \n",
        "\n",
        "<https://machinelearningmastery.com/randomness-in-machine-learning/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0FrUVd2RyU1",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to leverage the Keras `Sequential` api to estimate a feed forward neural networks on a dataset.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCMmF_iRyU1",
        "colab_type": "text"
      },
      "source": [
        "# JON CODY DS15 LECTURE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbmEcyjbRyU2",
        "colab_type": "text"
      },
      "source": [
        "Goals\n",
        "* Introduce the TensorFlow Keras API\n",
        "* Show an example of training model\n",
        "* Discuss Gradient Descent during the process\n",
        "* Optional: Investigate the TensorFlow / Keras Code for Dense Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS1pqHyZRyU3",
        "colab_type": "text"
      },
      "source": [
        "1. Import libraries / Tensorflow\n",
        "2. Define a model \n",
        "3. Compile the model\n",
        "4. Fit the model\n",
        "5. Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MAJSKo7RyU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiRA65VtRyU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting for 10 categories\n",
        "# DESIGNING THE CAR\n",
        "\n",
        "# model is a sequence of dense layers\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784), # number of neurons, activation, inputs- our 1st hidden layer\n",
        "                    Dense(5, activation='sigmoid'), # 2nd hidden layer\n",
        "                    Dense(10, activation='softmax')]) # output layer- softmax is for classification - multiclass version of sigmoid"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydmhINeaRyU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# complie the model\n",
        "# SELECT THE MECHANIC AND HOW UPDATES WILL HAPPEN\n",
        "# HOW THE MODEL WILL BE TRAINED\n",
        "\n",
        "model.compile(optimizer= SGD(), loss= 'sparse_categorical_crossentropy', metrics= ['accuracy']) # sparce_C_C = does 1 hot encoding"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va9D6kQwRyVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "f830ef0d-cbfb-4468-bf75-12107c61c24d"
      },
      "source": [
        "# check out the model\n",
        "# bias will add 5 parameters - SINCE 5 INPUTS\n",
        "# 1ST HIDDEN LAYER --> 5 INPUTS AND 784 VALUES --> (5*784) = 3920 + (5 BIAS PARAMS)\n",
        "# 2ND HIDDEN LAYER --> 5(1ST) * 5(2ND) + 5(BIAS) = 30 PARAMS\n",
        "# 3RD HIDDEN LAYER --> 5(2ND * 10(OUTPUT) + 5 (BIAS) = 60 PARAMS\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 5)                 3925      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                60        \n",
            "=================================================================\n",
            "Total params: 4,015\n",
            "Trainable params: 4,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaSYc7RoRyVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "735009b4-88ed-4012-a79f-2e9569b2c5a1"
      },
      "source": [
        "# get dataset\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GurjqmyrRyVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "3d00e099-8d68-4dd3-e5cb-3c5097991140"
      },
      "source": [
        "# look at data - numpy arrays actually\n",
        "\n",
        "print(X_train.shape) # not tablular 60000 images that are 28x28\n",
        "X_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPg1Agd0RyVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "aed27370-8e8d-445e-ad4e-6154bba3f315"
      },
      "source": [
        "# get a visual of first index\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_train[9]);\n",
        "print(y_train[9])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZOOLUNERyVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1e91d4d1-5434-4440-b605-b0b33f45a426"
      },
      "source": [
        "# reshaping data\n",
        "\n",
        "X_train = X_train.reshape((60000, 784)) # 28*28= 784\n",
        "print('X train:', X_train.shape)\n",
        "\n",
        "X_test = X_test.reshape((10000, 784))\n",
        "print('X test:', X_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train: (60000, 784)\n",
            "X test: (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPq6-nQsRyVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc897e29-dc1e-4edf-9599-659d0b944769"
      },
      "source": [
        "# look at our target\n",
        "\n",
        "print(y_train.shape)\n",
        "y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvUHMKHeRyVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "3849d16e-9ccb-4a92-dbb3-b97073637be1"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(X_train, y_train, epochs=25)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2069 - accuracy: 0.3170\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.0311 - accuracy: 0.4649\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.8272 - accuracy: 0.5461\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6400 - accuracy: 0.5629\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.4921 - accuracy: 0.5762\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3792 - accuracy: 0.5733\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3004 - accuracy: 0.5713\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2310 - accuracy: 0.6036\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1993 - accuracy: 0.6031\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1454 - accuracy: 0.5975\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1129 - accuracy: 0.6348\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1067 - accuracy: 0.6388\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0629 - accuracy: 0.6494\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0578 - accuracy: 0.6507\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0395 - accuracy: 0.6541\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0320 - accuracy: 0.6479\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0258 - accuracy: 0.6511\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0345 - accuracy: 0.6428\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0114 - accuracy: 0.6567\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0142 - accuracy: 0.6578\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9821 - accuracy: 0.6728\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9699 - accuracy: 0.6642\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9623 - accuracy: 0.6702\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9619 - accuracy: 0.6633\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9714 - accuracy: 0.6557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f312ee454e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ5Iq7FtRyVW",
        "colab_type": "text"
      },
      "source": [
        "## Stochastic Gradient Descent\n",
        "* Batches\n",
        "* Learning Rate\n",
        "* Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuACX9LmRyVX",
        "colab_type": "text"
      },
      "source": [
        "#### Batch Size\n",
        "- Number of observations the model is shown to make predictions and update the weights.\n",
        "- Selected randomly during each epoch.\n",
        "- All observations are considered when passing thru an epoch at some point.\n",
        "\n",
        "**Smaller Batch Size = Slower run time ( maybe have better results)** <br>\n",
        "**Default Batch Size = Balance between speed and accuracy** <br>\n",
        "**Large Batch Size = Very fast, but not as accurate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAxfTgHjRyVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the learning rate\n",
        "\n",
        "sgd_01 = SGD(learning_rate= 0.01)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SunNsDzARyVc",
        "colab_type": "text"
      },
      "source": [
        "#### Default Experiment\n",
        "\n",
        "_What changed from model above?_\n",
        "* Optimizer and Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFxLF1UxRyVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting for 10 categories\n",
        "# DESIGNING THE CAR\n",
        "\n",
        "# model is a sequence of dense layers\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784), # number of neurons, activation, inputs- our 1st hidden layer\n",
        "                    Dense(5, activation='sigmoid'), # 2nd hidden layer\n",
        "                    Dense(10, activation='softmax') # output layer- softmax is for classification - multiclass version of sigmoid\n",
        "])\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw6x1ycpRyVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model- default\n",
        "# SELECT THE MECHANIC AND HOW UPDATES WILL HAPPEN\n",
        "\n",
        "model.compile(optimizer= sgd_01, loss= 'sparse_categorical_crossentropy', metrics= ['accuracy']) # sparce_C_C = does 1 hot encoding"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FFQAF2YRyVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "b8f39d1a-b0c1-4489-9247-1e4305c75366"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "batch_default = model.fit(X_train, y_train,\n",
        "                         epochs= 25,\n",
        "                         batch_size= 32, # default batch size\n",
        "                         validation_data= (X_test, y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.1766 - accuracy: 0.2465 - val_loss: 2.0765 - val_accuracy: 0.3160\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.9909 - accuracy: 0.2763 - val_loss: 1.8961 - val_accuracy: 0.2916\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.8360 - accuracy: 0.3274 - val_loss: 1.7749 - val_accuracy: 0.4071\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.7345 - accuracy: 0.4076 - val_loss: 1.6754 - val_accuracy: 0.4430\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6552 - accuracy: 0.4554 - val_loss: 1.6407 - val_accuracy: 0.4478\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.5777 - accuracy: 0.4747 - val_loss: 1.5388 - val_accuracy: 0.4902\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.5345 - accuracy: 0.4647 - val_loss: 1.5495 - val_accuracy: 0.4291\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.5067 - accuracy: 0.4631 - val_loss: 1.4793 - val_accuracy: 0.4764\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.4943 - accuracy: 0.4593 - val_loss: 1.4548 - val_accuracy: 0.4777\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.4313 - accuracy: 0.4760 - val_loss: 1.4097 - val_accuracy: 0.4908\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.4151 - accuracy: 0.4769 - val_loss: 1.3744 - val_accuracy: 0.4828\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3694 - accuracy: 0.4884 - val_loss: 1.3732 - val_accuracy: 0.4882\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3769 - accuracy: 0.4800 - val_loss: 1.3641 - val_accuracy: 0.4724\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3604 - accuracy: 0.4719 - val_loss: 1.3175 - val_accuracy: 0.4792\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3568 - accuracy: 0.4679 - val_loss: 1.2848 - val_accuracy: 0.4905\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3051 - accuracy: 0.4713 - val_loss: 1.2758 - val_accuracy: 0.4848\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2892 - accuracy: 0.4819 - val_loss: 1.3521 - val_accuracy: 0.4755\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2735 - accuracy: 0.4846 - val_loss: 1.2480 - val_accuracy: 0.4835\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2911 - accuracy: 0.4868 - val_loss: 1.2399 - val_accuracy: 0.4874\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2779 - accuracy: 0.4930 - val_loss: 1.2479 - val_accuracy: 0.5025\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2376 - accuracy: 0.5142 - val_loss: 1.2323 - val_accuracy: 0.5206\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2241 - accuracy: 0.5228 - val_loss: 1.2032 - val_accuracy: 0.5301\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2239 - accuracy: 0.5322 - val_loss: 1.1883 - val_accuracy: 0.5448\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1910 - accuracy: 0.5481 - val_loss: 1.2333 - val_accuracy: 0.5086\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1846 - accuracy: 0.5541 - val_loss: 1.1546 - val_accuracy: 0.5699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp1fD6H97_9p",
        "colab_type": "text"
      },
      "source": [
        "#### Small Batch Size Experiment\n",
        "\n",
        "_What changed from model above?_\n",
        "* Batch size is 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvD2m0D8RyVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting for 10 categories\n",
        "# DESIGNING THE CAR\n",
        "\n",
        "# model is a sequence of dense layers\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784), # number of neurons, activation, inputs- our 1st hidden layer\n",
        "                    Dense(5, activation='sigmoid'), # 2nd hidden layer\n",
        "                    Dense(10, activation='softmax') # output layer- softmax is for classification - multiclass version of sigmoid\n",
        "])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU3EcVlL8YGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model- default\n",
        "# SELECT THE MECHANIC AND HOW UPDATES WILL HAPPEN\n",
        "# NEED TO RECOMPILE TO RERUN MODEL - RESETS THE STATE\n",
        "\n",
        "model.compile(optimizer= sgd_01, loss= 'sparse_categorical_crossentropy', metrics= ['accuracy']) # sparce_C_C = does 1 hot encoding"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmgQ5idt8d1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "a49bdc07-9b7d-414f-dc4f-2ea8bca87b50"
      },
      "source": [
        "# fit the model- small batch\n",
        "# can change runtime = GPU -if GPU is good \n",
        "\n",
        "batch_small = model.fit(X_train, y_train,\n",
        "                         epochs= 25,\n",
        "                         batch_size= 1, # changed\n",
        "                         validation_data= (X_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 2.2711 - accuracy: 0.1366 - val_loss: 2.3059 - val_accuracy: 0.1135\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.1877 - accuracy: 0.1610 - val_loss: 2.0678 - val_accuracy: 0.2075\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0017 - accuracy: 0.2353 - val_loss: 1.9317 - val_accuracy: 0.2812\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 1.9592 - accuracy: 0.2484 - val_loss: 2.1481 - val_accuracy: 0.1771\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 2.0102 - accuracy: 0.2223 - val_loss: 2.0601 - val_accuracy: 0.2095\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0666 - accuracy: 0.1979 - val_loss: 2.0437 - val_accuracy: 0.2113\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0512 - accuracy: 0.1950 - val_loss: 2.1086 - val_accuracy: 0.1804\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0201 - accuracy: 0.1927 - val_loss: 2.0147 - val_accuracy: 0.1865\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0429 - accuracy: 0.2047 - val_loss: 2.0120 - val_accuracy: 0.2106\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 68s 1ms/step - loss: 2.0182 - accuracy: 0.2086 - val_loss: 1.9862 - val_accuracy: 0.2099\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0055 - accuracy: 0.1949 - val_loss: 2.0419 - val_accuracy: 0.1915\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.1126 - accuracy: 0.1773 - val_loss: 2.1745 - val_accuracy: 0.1733\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.1648 - accuracy: 0.1649 - val_loss: 2.1124 - val_accuracy: 0.1830\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.1117 - accuracy: 0.1783 - val_loss: 2.0759 - val_accuracy: 0.1755\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 2.0326 - accuracy: 0.1910 - val_loss: 1.9654 - val_accuracy: 0.2089\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 1.9796 - accuracy: 0.2045 - val_loss: 1.9703 - val_accuracy: 0.2096\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 1.9726 - accuracy: 0.2077 - val_loss: 1.9734 - val_accuracy: 0.2102\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 1.9828 - accuracy: 0.1973 - val_loss: 1.9906 - val_accuracy: 0.1828\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 68s 1ms/step - loss: 1.9686 - accuracy: 0.2000 - val_loss: 1.9579 - val_accuracy: 0.2033\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 1.9560 - accuracy: 0.2046 - val_loss: 1.9477 - val_accuracy: 0.2108\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 1.9423 - accuracy: 0.2053 - val_loss: 1.9506 - val_accuracy: 0.1811\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 1.9759 - accuracy: 0.2004 - val_loss: 2.0136 - val_accuracy: 0.1980\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0131 - accuracy: 0.1938 - val_loss: 2.0325 - val_accuracy: 0.1963\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 2.0896 - accuracy: 0.1838 - val_loss: 2.0985 - val_accuracy: 0.1862\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 2.0842 - accuracy: 0.1858 - val_loss: 2.0880 - val_accuracy: 0.1871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gElNulhMBXTe",
        "colab_type": "text"
      },
      "source": [
        "#### Large Batch Size Experiment\n",
        "\n",
        "_What changed from model above?_\n",
        "* Batch size is 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJabiVQBWuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting for 10 categories\n",
        "# DESIGNING THE CAR\n",
        "\n",
        "# model is a sequence of dense layers\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784), # number of neurons, activation, inputs- our 1st hidden layer\n",
        "                    Dense(5, activation='sigmoid'), # 2nd hidden layer\n",
        "                    Dense(10, activation='softmax') # output layer- softmax is for classification - multiclass version of sigmoid\n",
        "])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS1wTdCGBfYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model- default\n",
        "# SELECT THE MECHANIC AND HOW UPDATES WILL HAPPEN\n",
        "# NEED TO RECOMPILE TO RERUN MODEL - RESETS THE STATE\n",
        "\n",
        "model.compile(optimizer= sgd_01, loss= 'sparse_categorical_crossentropy', metrics= ['accuracy']) # sparce_C_C = does 1 hot encoding"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KERbMH4YBh58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "edf594fd-a99c-46bd-a22c-960207dab98b"
      },
      "source": [
        "# fit the model- large batch\n",
        "\n",
        "\n",
        "batch_large = model.fit(X_train, y_train,\n",
        "                         epochs= 25,\n",
        "                         batch_size= 512, # changed\n",
        "                         validation_data= (X_test, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 2.3507 - accuracy: 0.1654 - val_loss: 2.3193 - val_accuracy: 0.1999\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2979 - accuracy: 0.2042 - val_loss: 2.2795 - val_accuracy: 0.2073\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2667 - accuracy: 0.2086 - val_loss: 2.2537 - val_accuracy: 0.2097\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2441 - accuracy: 0.2107 - val_loss: 2.2349 - val_accuracy: 0.2107\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2267 - accuracy: 0.2113 - val_loss: 2.2191 - val_accuracy: 0.2110\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.2120 - accuracy: 0.2115 - val_loss: 2.2052 - val_accuracy: 0.2106\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1988 - accuracy: 0.2112 - val_loss: 2.1925 - val_accuracy: 0.2108\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1858 - accuracy: 0.2118 - val_loss: 2.1796 - val_accuracy: 0.2111\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1732 - accuracy: 0.2118 - val_loss: 2.1675 - val_accuracy: 0.2117\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1611 - accuracy: 0.2783 - val_loss: 2.1575 - val_accuracy: 0.2705\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1493 - accuracy: 0.2864 - val_loss: 2.1441 - val_accuracy: 0.2814\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1371 - accuracy: 0.3467 - val_loss: 2.1322 - val_accuracy: 0.3571\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1250 - accuracy: 0.3602 - val_loss: 2.1196 - val_accuracy: 0.3612\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1125 - accuracy: 0.3611 - val_loss: 2.1074 - val_accuracy: 0.3649\n",
            "Epoch 15/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0999 - accuracy: 0.3633 - val_loss: 2.0959 - val_accuracy: 0.3602\n",
            "Epoch 16/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0877 - accuracy: 0.3638 - val_loss: 2.0824 - val_accuracy: 0.3648\n",
            "Epoch 17/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0748 - accuracy: 0.3656 - val_loss: 2.0699 - val_accuracy: 0.3653\n",
            "Epoch 18/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0619 - accuracy: 0.3678 - val_loss: 2.0575 - val_accuracy: 0.3687\n",
            "Epoch 19/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.0488 - accuracy: 0.3685 - val_loss: 2.0481 - val_accuracy: 0.3750\n",
            "Epoch 20/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.0357 - accuracy: 0.3713 - val_loss: 2.0313 - val_accuracy: 0.3703\n",
            "Epoch 21/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.0219 - accuracy: 0.3701 - val_loss: 2.0173 - val_accuracy: 0.3703\n",
            "Epoch 22/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0081 - accuracy: 0.3697 - val_loss: 2.0039 - val_accuracy: 0.3700\n",
            "Epoch 23/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.9946 - accuracy: 0.3716 - val_loss: 1.9904 - val_accuracy: 0.3720\n",
            "Epoch 24/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.9814 - accuracy: 0.3700 - val_loss: 1.9779 - val_accuracy: 0.3712\n",
            "Epoch 25/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9680 - accuracy: 0.3728 - val_loss: 1.9635 - val_accuracy: 0.3745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTta9k7nAllx",
        "colab_type": "text"
      },
      "source": [
        "#### Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFRKrfBnArPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c6e824d2-3808-487e-a178-b8d59e706794"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S24mfxHqAsCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # not working - ?\n",
        "\n",
        "# results = pd.DataFrame()\n",
        "\n",
        "# for i, m in enumerate([batch_default, batch_small, batch_large]):\n",
        "\n",
        "#   temp = pd.DataFrame.from_dict(m.history)\n",
        "#   temp['epoch'] = temp.index.values\n",
        "#   temp['model'] = i\n",
        "\n",
        "#   results.append(temp, ignore_index = True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F4h5v7S0wo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this instead\n",
        "# gather all data from all dataframes\n",
        "\n",
        "# default batch\n",
        "default = pd.DataFrame.from_dict(batch_default.history)\n",
        "default['epoch'] = default.index.values\n",
        "default['batch_size'] = 'Default: 32'\n",
        "\n",
        "# small batch\n",
        "small = pd.DataFrame.from_dict(batch_small.history)\n",
        "small['epoch'] = small.index.values\n",
        "small['batch_size'] = 'Small: 1'\n",
        "\n",
        "# large batch\n",
        "large = pd.DataFrame.from_dict(batch_large.history)\n",
        "large['epoch'] = large.index.values\n",
        "large['batch_size'] = 'Large: 512'\n",
        "\n",
        "df = pd.concat([default, small, large])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LnB5QSz0wvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0ed71c33-ce22-4f28-fd81-eae0fe543906"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.176607</td>\n",
              "      <td>0.246500</td>\n",
              "      <td>2.076453</td>\n",
              "      <td>0.3160</td>\n",
              "      <td>0</td>\n",
              "      <td>Default: 32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.990925</td>\n",
              "      <td>0.276350</td>\n",
              "      <td>1.896067</td>\n",
              "      <td>0.2916</td>\n",
              "      <td>1</td>\n",
              "      <td>Default: 32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.835994</td>\n",
              "      <td>0.327383</td>\n",
              "      <td>1.774942</td>\n",
              "      <td>0.4071</td>\n",
              "      <td>2</td>\n",
              "      <td>Default: 32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.734482</td>\n",
              "      <td>0.407583</td>\n",
              "      <td>1.675401</td>\n",
              "      <td>0.4430</td>\n",
              "      <td>3</td>\n",
              "      <td>Default: 32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.655234</td>\n",
              "      <td>0.455400</td>\n",
              "      <td>1.640651</td>\n",
              "      <td>0.4478</td>\n",
              "      <td>4</td>\n",
              "      <td>Default: 32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epoch   batch_size\n",
              "0  2.176607  0.246500  2.076453        0.3160      0  Default: 32\n",
              "1  1.990925  0.276350  1.896067        0.2916      1  Default: 32\n",
              "2  1.835994  0.327383  1.774942        0.4071      2  Default: 32\n",
              "3  1.734482  0.407583  1.675401        0.4430      3  Default: 32\n",
              "4  1.655234  0.455400  1.640651        0.4478      4  Default: 32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUdgmx90w16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b07b6354-387f-40ad-df7b-97b7745c2863"
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_accuracy', hue='batch_size', data= df);"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSHftkzs0xCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4d6f9e9a-8be0-47f4-a5ab-ee0073d188fb"
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_loss', hue='batch_size', data= df);"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vNPelNJ4EK2",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate\n",
        "\n",
        "Learning rate controls the size of the update to our weights that the optimizer algorthim matke. THIS IS VERY IMPORTANT HYPERPERAMERTER.\n",
        "\n",
        "* Too high of a learning rate causes unstable results\n",
        "* Too low of a learning rate - model will never 'converge'\n",
        "* Goldy Locks parameters - it needsbe 'just right'\n",
        "* Scale of 0 - 1 \n",
        "\n",
        "Repeat the same experiment from batch size but change the learning rates.\n",
        "* Default rate = 0.01\n",
        "* Low rate = 0.0001\n",
        "* High rate = 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiyxrY4Q5Xa4",
        "colab_type": "text"
      },
      "source": [
        "## Default Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kRzkof65PNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "7416b6df-701e-40f7-91bd-6b8e8588c2c8"
      },
      "source": [
        "sgd = SGD(learning_rate= 0.01)\n",
        "\n",
        "# predict\n",
        "model = Sequential([\n",
        "                    Dense(5,activation= 'sigmoid', input_dim= 784),\n",
        "                    Dense(5,activation= 'sigmoid'),\n",
        "                    Dense(10,activation= 'softmax')\n",
        "                    ])\n",
        "# compile\n",
        "model.compile(optimizer= sgd, loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# fit the model- default Learning rate\n",
        "lr_default = model.fit(X_train, y_train,\n",
        "                         epochs= 25,\n",
        "                         batch_size= 32, # changed\n",
        "                         validation_data= (X_test, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.1572 - accuracy: 0.2147 - val_loss: 2.0349 - val_accuracy: 0.2701\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.9479 - accuracy: 0.3325 - val_loss: 1.8567 - val_accuracy: 0.4427\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 1.7978 - accuracy: 0.4575 - val_loss: 1.7216 - val_accuracy: 0.4766\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6744 - accuracy: 0.5387 - val_loss: 1.5998 - val_accuracy: 0.5565\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.5750 - accuracy: 0.5552 - val_loss: 1.5040 - val_accuracy: 0.5835\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.4913 - accuracy: 0.5538 - val_loss: 1.4109 - val_accuracy: 0.5887\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.4065 - accuracy: 0.5612 - val_loss: 1.3566 - val_accuracy: 0.6134\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3249 - accuracy: 0.5986 - val_loss: 1.2973 - val_accuracy: 0.5952\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2750 - accuracy: 0.6080 - val_loss: 1.1865 - val_accuracy: 0.6446\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 1.2090 - accuracy: 0.6182 - val_loss: 1.1309 - val_accuracy: 0.6442\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1321 - accuracy: 0.6408 - val_loss: 1.0927 - val_accuracy: 0.6733\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1202 - accuracy: 0.6475 - val_loss: 1.0327 - val_accuracy: 0.6807\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0833 - accuracy: 0.6712 - val_loss: 1.0849 - val_accuracy: 0.6997\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0657 - accuracy: 0.6838 - val_loss: 1.0085 - val_accuracy: 0.7393\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0031 - accuracy: 0.7192 - val_loss: 0.9282 - val_accuracy: 0.7454\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9803 - accuracy: 0.7235 - val_loss: 0.9198 - val_accuracy: 0.7490\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9609 - accuracy: 0.7201 - val_loss: 0.9181 - val_accuracy: 0.7431\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.9468 - accuracy: 0.7433 - val_loss: 0.9944 - val_accuracy: 0.7042\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.9237 - accuracy: 0.7350 - val_loss: 0.8766 - val_accuracy: 0.7413\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8951 - accuracy: 0.7417 - val_loss: 0.8855 - val_accuracy: 0.7417\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.9010 - accuracy: 0.7333 - val_loss: 0.8649 - val_accuracy: 0.7491\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8621 - accuracy: 0.7542 - val_loss: 0.8619 - val_accuracy: 0.7465\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8573 - accuracy: 0.7578 - val_loss: 0.8427 - val_accuracy: 0.7537\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8641 - accuracy: 0.7506 - val_loss: 0.9058 - val_accuracy: 0.7448\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8625 - accuracy: 0.7571 - val_loss: 0.9169 - val_accuracy: 0.7356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wajy2c8FKKnH",
        "colab_type": "text"
      },
      "source": [
        "## Low Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "783RdDjSKJBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "bf832bfc-72fa-47ab-9f38-2b2d887cde3e"
      },
      "source": [
        "sgd = SGD(learning_rate= 0.0001)\n",
        "\n",
        "# predict\n",
        "model = Sequential([\n",
        "                    Dense(5,activation= 'sigmoid', input_dim= 784),\n",
        "                    Dense(5,activation= 'sigmoid'),\n",
        "                    Dense(10,activation= 'softmax')\n",
        "                    ])\n",
        "# compile\n",
        "model.compile(optimizer= sgd, loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# fit the model- low Learning rate\n",
        "lr_low = model.fit(X_train, y_train,\n",
        "                         epochs= 25,\n",
        "                         batch_size= 32, # changed\n",
        "                         validation_data= (X_test, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3735 - accuracy: 0.0904 - val_loss: 2.3665 - val_accuracy: 0.0892\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3594 - accuracy: 0.0904 - val_loss: 2.3532 - val_accuracy: 0.0892\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3483 - accuracy: 0.0904 - val_loss: 2.3431 - val_accuracy: 0.0892\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3397 - accuracy: 0.0904 - val_loss: 2.3359 - val_accuracy: 0.0892\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3329 - accuracy: 0.0904 - val_loss: 2.3298 - val_accuracy: 0.0892\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3272 - accuracy: 0.0904 - val_loss: 2.3249 - val_accuracy: 0.0892\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3226 - accuracy: 0.0904 - val_loss: 2.3206 - val_accuracy: 0.0892\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3186 - accuracy: 0.0904 - val_loss: 2.3166 - val_accuracy: 0.0892\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3149 - accuracy: 0.0904 - val_loss: 2.3130 - val_accuracy: 0.0892\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3114 - accuracy: 0.0904 - val_loss: 2.3096 - val_accuracy: 0.0892\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3080 - accuracy: 0.0904 - val_loss: 2.3061 - val_accuracy: 0.0892\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3047 - accuracy: 0.0904 - val_loss: 2.3028 - val_accuracy: 0.0892\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3017 - accuracy: 0.0903 - val_loss: 2.2998 - val_accuracy: 0.0891\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2988 - accuracy: 0.0903 - val_loss: 2.2969 - val_accuracy: 0.0891\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2959 - accuracy: 0.0903 - val_loss: 2.2942 - val_accuracy: 0.0891\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2932 - accuracy: 0.0903 - val_loss: 2.2915 - val_accuracy: 0.0891\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2907 - accuracy: 0.0903 - val_loss: 2.2889 - val_accuracy: 0.0891\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2882 - accuracy: 0.0900 - val_loss: 2.2864 - val_accuracy: 0.0890\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2859 - accuracy: 0.0955 - val_loss: 2.2841 - val_accuracy: 0.0978\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2836 - accuracy: 0.0969 - val_loss: 2.2819 - val_accuracy: 0.0971\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2816 - accuracy: 0.0966 - val_loss: 2.2800 - val_accuracy: 0.0963\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2795 - accuracy: 0.0975 - val_loss: 2.2781 - val_accuracy: 0.0971\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2776 - accuracy: 0.1185 - val_loss: 2.2763 - val_accuracy: 0.1362\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2758 - accuracy: 0.1375 - val_loss: 2.2747 - val_accuracy: 0.1362\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.2741 - accuracy: 0.1427 - val_loss: 2.2729 - val_accuracy: 0.1488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIFmPmZ2KWqo",
        "colab_type": "text"
      },
      "source": [
        "## High Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH0mXLg6KYlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "e26503fe-b6b8-4045-abde-88d61fc66b14"
      },
      "source": [
        "sgd = SGD(learning_rate= 0.75)\n",
        "\n",
        "# predict\n",
        "model = Sequential([\n",
        "                    Dense(5,activation= 'sigmoid', input_dim= 784),\n",
        "                    Dense(5,activation= 'sigmoid'),\n",
        "                    Dense(10,activation= 'softmax')\n",
        "                    ])\n",
        "# compile\n",
        "model.compile(optimizer= sgd, loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# fit the model- high Learning rate\n",
        "lr_high = model.fit(X_train, y_train,\n",
        "                         epochs= 25,\n",
        "                         batch_size= 32, # changed\n",
        "                         validation_data= (X_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3088 - accuracy: 0.1041 - val_loss: 2.3050 - val_accuracy: 0.1009\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3065 - accuracy: 0.1043 - val_loss: 2.3132 - val_accuracy: 0.0958\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3068 - accuracy: 0.1033 - val_loss: 2.3043 - val_accuracy: 0.0958\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3067 - accuracy: 0.1052 - val_loss: 2.3071 - val_accuracy: 0.0980\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3064 - accuracy: 0.1039 - val_loss: 2.3063 - val_accuracy: 0.1010\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3065 - accuracy: 0.1050 - val_loss: 2.3077 - val_accuracy: 0.1028\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3066 - accuracy: 0.1051 - val_loss: 2.3048 - val_accuracy: 0.1032\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3070 - accuracy: 0.1033 - val_loss: 2.3046 - val_accuracy: 0.1135\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3066 - accuracy: 0.1039 - val_loss: 2.3067 - val_accuracy: 0.1135\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3067 - accuracy: 0.1071 - val_loss: 2.3047 - val_accuracy: 0.1135\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3066 - accuracy: 0.1047 - val_loss: 2.3065 - val_accuracy: 0.1135\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3066 - accuracy: 0.1042 - val_loss: 2.3042 - val_accuracy: 0.0974\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3066 - accuracy: 0.1063 - val_loss: 2.3055 - val_accuracy: 0.0974\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3064 - accuracy: 0.1067 - val_loss: 2.3041 - val_accuracy: 0.1028\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3065 - accuracy: 0.1060 - val_loss: 2.3040 - val_accuracy: 0.1032\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3067 - accuracy: 0.1045 - val_loss: 2.3036 - val_accuracy: 0.1135\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3066 - accuracy: 0.1057 - val_loss: 2.3074 - val_accuracy: 0.1028\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3069 - accuracy: 0.1040 - val_loss: 2.3067 - val_accuracy: 0.0982\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3069 - accuracy: 0.1047 - val_loss: 2.3053 - val_accuracy: 0.1135\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3068 - accuracy: 0.1056 - val_loss: 2.3048 - val_accuracy: 0.1032\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3068 - accuracy: 0.1038 - val_loss: 2.3065 - val_accuracy: 0.1135\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3070 - accuracy: 0.1033 - val_loss: 2.3026 - val_accuracy: 0.1010\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3065 - accuracy: 0.1052 - val_loss: 2.3100 - val_accuracy: 0.1009\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 2.3065 - accuracy: 0.1053 - val_loss: 2.3060 - val_accuracy: 0.1135\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3065 - accuracy: 0.1068 - val_loss: 2.3096 - val_accuracy: 0.1028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ns7hyJ2K4sL"
      },
      "source": [
        "## Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWeDLkHWK4s9",
        "colab": {}
      },
      "source": [
        "# gather all data from all dataframes\n",
        "\n",
        "# default learning rate\n",
        "default = pd.DataFrame.from_dict(lr_default.history)\n",
        "default['epoch'] = default.index.values\n",
        "default['learning_rate'] = 'Default: 0.01'\n",
        "\n",
        "# low learning rate\n",
        "low = pd.DataFrame.from_dict(lr_low.history)\n",
        "low['epoch'] = small.index.values\n",
        "low['learning_rate'] = 'Low: 0.0001'\n",
        "\n",
        "# high learning rate\n",
        "high = pd.DataFrame.from_dict(lr_high.history)\n",
        "high['epoch'] = high.index.values\n",
        "high['learning_rate'] = 'High: 0.75'\n",
        "\n",
        "df = pd.concat([default, low, high])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "65fpfmYFK4tG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "daddab2e-e30a-4563-de12-2cc729e27df0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "      <th>learning_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.157223</td>\n",
              "      <td>0.214700</td>\n",
              "      <td>2.034883</td>\n",
              "      <td>0.2701</td>\n",
              "      <td>0</td>\n",
              "      <td>Default: 0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.947854</td>\n",
              "      <td>0.332533</td>\n",
              "      <td>1.856748</td>\n",
              "      <td>0.4427</td>\n",
              "      <td>1</td>\n",
              "      <td>Default: 0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.797774</td>\n",
              "      <td>0.457450</td>\n",
              "      <td>1.721597</td>\n",
              "      <td>0.4766</td>\n",
              "      <td>2</td>\n",
              "      <td>Default: 0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.674366</td>\n",
              "      <td>0.538667</td>\n",
              "      <td>1.599788</td>\n",
              "      <td>0.5565</td>\n",
              "      <td>3</td>\n",
              "      <td>Default: 0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.575019</td>\n",
              "      <td>0.555250</td>\n",
              "      <td>1.503993</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>4</td>\n",
              "      <td>Default: 0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epoch  learning_rate\n",
              "0  2.157223  0.214700  2.034883        0.2701      0  Default: 0.01\n",
              "1  1.947854  0.332533  1.856748        0.4427      1  Default: 0.01\n",
              "2  1.797774  0.457450  1.721597        0.4766      2  Default: 0.01\n",
              "3  1.674366  0.538667  1.599788        0.5565      3  Default: 0.01\n",
              "4  1.575019  0.555250  1.503993        0.5835      4  Default: 0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ldG0YrllK4tP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "efedca2b-07f6-45b6-abe5-8733280f4eae"
      },
      "source": [
        "sns.lineplot(x='epoch', y='loss', hue='learning_rate', data= df);"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L4rjZwEjK4tX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ad4c0ba2-4760-4c6b-b9f6-c176555a1dee"
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_loss', hue='learning_rate', data= df);"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wUdfrA8c+zJZtKSCAgJEDovYeigg0RRE/E7qmoJyLW834eljvvRL2ip6inHiKKB9gVe0c9FVRQEgi9CgiBSEICIQkpW76/P3azZiENyGaT7PN+veY1szPfmXkmm51n6vcrxhiUUkqpCpZQB6CUUqpx0cSglFIqgCYGpZRSATQxKKWUCqCJQSmlVABbqAM4Fq1btzapqamhDkMppZqUjIyMfcaYpNrKNcnEkJqaSnp6eqjDUEqpJkVEfq5LOb2UpJRSKkBQE4OIdBCRr0RkvYisE5Hf11B2mIi4ROSiYMaklFKqZsG+lOQC7jDGrBCROCBDRD43xqyvXEhErMDDwKIgx6OUUqoWQT1jMMZkG2NW+IYLgQ1AchVFbwXeAnKCGY9SSqnaNdg9BhFJBQYDPxw2PhmYBDxTy/xTRSRdRNJzc3ODFaZSSoW9BkkMIhKL94zgdmPMwcMmPwHcZYzx1LQMY8wcY0yaMSYtKanWp62UUkodo6A/rioidrxJ4WVjzNtVFEkDXhMRgNbABBFxGWPeDXZsSimljhTUxCDevf1cYIMx5rGqyhhjOlcqPw/4MGhJISsDtn4BCamQ2BkSOkNMa/AmJaWUUgT/jOFk4CpgjYhk+sb9CegIYIyZHeT1B8paDl//I3BcRJwvUaR6E0VFwkjsDC1SwNok3wFUSqljJk2xoZ60tDRzzG8+O0tg/8+wfwfs3w7523/tH/gZ3OW/lrXYIL4DtOwILdpD3AkQ5+tXfI5tC1Z7vWyXUkoFk4hkGGPSaisXfofD9iho08vbHc7jhoN7KiWMHd7hgizYvgSKfgGP67CZBGKSoEU7iKvUxbSCqESITqzUTwB7tF66Uko1auGXGGpisULLDt6u8ylHTvd44NA+KMyGwl+8SaTwFyj09Qt2Q1a6t0x1rI4jk0VFP7IlRMb7uhaHfY4HmyN4266UUj6aGI6GxQKxbbxdu4HVl3OVQ0k+lOyHQ/ne4SP6+7393E3eciX5VZyNHMYWGZgoHHEQEVupH+vtVx52xHrvo/inxXjPWmwOPXNRSlVJE0Mw2CJ89yNOqPs8xnjvf5QWVNEdOHJc2UEoPeg9aykrgvJCb9+467Y+sf6aJCKiwR7j60dXGh/jG47yfvaXrWLYHvXrfPZovWmvVBOmv17AGMMh1yHyS/PJL81nf+n+gGGA1lGtaRXVilaRrfzDCY4ErBZr/QQh4t3RRkR771cc24aAqzQwUZQX/dovL4LyYm/nPATlh8BZ7O2XF3uHywqhaO9hZQ4BR/mQgsXmOzOJBHtkpeEob2fz9e2RvuHj7GsiUiFgjKHEVcKBsgMcch7CYXMQZYsi2haNw+qol/2D2+Om1F1KqauUUncpcRFxtIhoUQ/RVy+sfk0rc1byxc9fBO74y/aTX5JPuae8ynmibFEYYyh1lx4xzSIWWjpaehNFZCtaRXmTRmJkIgDl7nLK3GU4PU7K3GWUu8u9ncc33u0b7ynH6XZiEQsWsSAiWMWKIEeOE8GCdxyAy7hwe9y4jfuIvsu48Hg83mGPC4/xYLVYcVgd2C12HFYHDocDe3QEDmscEdYIIiwROKwO77CvEwN4XIjHDR4nuJ2Ix4m4Xb8Oe3zDbicedzlOdzkudzlOj2/Y48LpceL0HMDl3Iez3I3TuHEZN07jwWI82Dxu7MZgA2/fgA1T5bAVgxvBLeBCcFksuCw2XFYbLosNt8WCS6y4LFbvNLFgxILdYvN2YsNusWO32rFZIrBb7ditDuzWCG/fFonN5gCLHY945/dYBLdY8IgFtwhuBA8Gt3HjMR5cHhcGg0UsWMWKVaxYLBZsYvt1nMWKRSqN830WvJf1/P3DLvNVfK5cTkQCylc7zve5zF3m38GUuEp+7VfsdFyllLhL/MPlnnIseP/3/P+Hh/1PVvwv+stgqXIbK7bdKtaAv0/l7a+It6rPFb+3ir+D2+P2/09V/H9X9Ct3FeOsFiuR1kiibFFE2rz9iuGK8ZWnOawOipxFHCg7wIHSA95+2QH2l+6noKyA/WX7/dOq23cAOKwO/zIrr6eiExH/d1HmLgsYrkgETo8zYJl3DbuLK/tcWe0660NYJYYt+7fw5uY3SYxMJMGRQOuo1vRI6OH9HJkQ0K8YrkgMh1yHyCvJY1/JPvJK8wKG95XsI78kn52FO9lXso8yd5l/nRaxBOyI/Ttc3w7YbrUTa4/F5rBhjMGDB2O8OxtjjH+H4zEe/zSP8eDx1SBis9j8PzabxYZDvEcplX+UNrH5f4AVP6Yyd5k/ORU5i6pMYBXjjpVNbL4drw273Y7N4sBuicVu8Y2r2DGLDReGQx4nLrfTl0ic3kTidnpjNk5cnopE8uvlMhsWbCLY8HZWBBvef2xvMnFjMy6sHgPGg8sYXHhwYnCCtxNwiuASwVnH+y4WY7AAVuOtV8aGt29B8AjepAW4BTwYarl7FBIVO63Dd4zRtmgSIxOxW+wYzK//c5X//yoNV/zfuj1uXLhwu70HJx7jCTg4CTh4OSyZGmMwGP//deXlYvCvz/jOXCv+p20Wm/83YLPYsInvsyXws9u4/TvdygmxrgQh3hFPS0dLWjpa0j62PX1a9SHBkUC8I56EyASibdEBO/cSVwkl7hJKnCX+9VVMO1h+kL2H9mKM8SYim4MWjha0iW7j/04q+g6bgyirt0ykNZIBSQOC8v8QsL3h9B6Dx3j8Rx/BUpFEBCHCGoHN0vRzb8X/SMUP2D+M8V9h8n/G+yOyWWxB+1tX7JAqH0EeM4/be/nNVQbOEoyzBJezGGd5Mc7yQnCXY3O7sLjLsLqcWNzlWF3liLvMO4+rtFJXVqlfBv4y3s7jLsXtKsftKsPjLsPlLsfjcVKR5vy/RAn8bHwjDIePByO+PmAsDrBFYKx2jDWwj9VBpDWCSKt35xJpjcBij/Q+JWeLAKuvszkOG/bO6/0ccdjw4fNVKmu1/zrNUr//B8aY4//e8e4PKu/I/TtzVwll7jJi7DHenb4jgbiIuPq7bBxC+h5DFYKdFMB7+h5jjwn6ehpSwGWMRvAgU8VltXphsf56kx3v5tl9XX2z+LqAZXs83pcqKycRd/mRiaXWceXV9Et/HXY7oawY3PsrzeusVN5Xrub6LI+eWCslEXulJFKROGyVpttqHS8Wm3d+i9073mL3fa483h447J9m889nsdiJstqJ8k+LgqgW3v8JS6X56zmxNQVhlRiUanQsFrD4btA3Fh73rwnH7fw1CR2RTA5PLBWfnb+Wr5juHy4PHHaV++5blYPb5X3YwX3A++i2v2ylYf94J0f9QMQxk0pJwvZrMqpyuNJni7VSMjqss9p9CahyYrNWs1x74Hzth1T9gm490sSglApksXqfjiM61JHUzOP2JgjfAxEBScP3MIR3miuwTMC0qspWV76m4crzVupcpb4y7l/LeVyVYq8YV2lbajtjG/dPTQxKKVUli9Xb0YjOtuqDx1MpuVSRrKISgh6CJgallGpMLBawRAARoQshZGtWSinVKGliUEopFUATg1JKqQCaGJRSSgUIamIQkQ4i8pWIrBeRdSLy+yrKXCEiq0VkjYh8LyI11GetlFIq2IL9VJILuMMYs0JE4oAMEfncGLO+UpntwKnGmP0icjYwBxgR5LiUUkpVI6iJwRiTDWT7hgtFZAOQDKyvVOb7SrMsA1KCGZNSSqmaNdg9BhFJBQYDP9RQ7Drgk2rmnyoi6SKSnpubW/8BKqWUAhooMYhILPAWcLsx5mA1ZU7Hmxjuqmq6MWaOMSbNGJOWlJQUvGCVUirMBf3NZxGx400KLxtj3q6mzADgeeBsY0xesGNSSilVvWA/lSTAXGCDMeaxasp0BN4GrjLGbA5mPEoppWoX7DOGk4GrgDUikukb9yegI4AxZjbwV6AVMMtX77+rLg1JKKWUCo5gP5X0LbU07WKMmQJMCWYcSiml6k7ffFZKKRVAE4NSSqkAmhiUUkoF0MSglFIqgCYGpZRSATQxKKWUCqCJQSmlVABNDEoppQJoYlBKKRVAE4NSSqkAmhiUUkoF0MSglFIqgCYGpZRSATQxKKWUChBWiWFrThGPfLYRY0yoQ1FKqUYrrBLDsm15/Oern/h8/d5Qh6KUUo1WWCWGS4d1oEtSDA99uhGX2xPqcJRSqlEKdpvPHUTkKxFZLyLrROT3VZQREXlSRLaKyGoRGRKseOxWC3eP78W23GJeW74rWKtRSqkmLdhnDC7gDmNMH2AkcLOI9DmszNlAd183FXgmmAGN7dOWYakJPPHFZorKXMFclVJKNUlBTQzGmGxjzArfcCGwAUg+rNhEYIHxWga0FJF2wYpJRPjThN7sKypnzuJtwVqNUko1WQ12j0FEUoHBwA+HTUoGKl/XyeLI5IGITBWRdBFJz83NPa5YBndM4Jz+7Xhu8TZyDpYe17KUUqq5aZDEICKxwFvA7caYg8eyDGPMHGNMmjEmLSkp6bhjunN8T1weD49/sfm4l6WUUs1J0BODiNjxJoWXjTFvV1FkN9Ch0ucU37ig6tQqhitGdOL15bvYsrcw2KtTSqkmI9hPJQkwF9hgjHmsmmLvA5N9TyeNBAqMMdnBjKvCbWO6ExNh46FPNjbE6pRSqkkI9hnDycBVwBkikunrJojINBGZ5ivzMbAN2Ao8B9wU5Jj8EmMiuPH0rny5MYelP+U11GqVUqpRk6ZYPURaWppJT0+vl2WVOt2c/ujXJMU5ePemk7FYpF6Wq5RSjY2IZBhj0morF1ZvPlcl0m7ljrN6sjqrgA/XNMgVLKWUatTCPjEATBqcTO92LfjXpxspc7lDHY5SSoWUJgbAahHuObsXWftLeHHpz6EORymlQkoTg88pPZIY3b01T/1vKwWHnKEORymlQkYTQyX3nN2bg6VOZn29NdShKKVUyGhiqKRP+xZcMDiF/36/g6z9h0IdjlJKhYQmhsPccVYPBJi5SKvKUEqFJ00Mh2nfMorfjerMOyt3s3Z3QajDUUqpBqeJoQo3ntaVhGg7//xkg7YPrZQKO5oYqtAi0s5tY7rz3dY8vtl8fFV8K6VUU6OJoRpXjOhEp1bR/PPjjbg9etaglAofmhiqEWGzcOe4XmzaW8hbGVmhDkcppRqMJoYaTOh/AoM7tuSfn2zglwJt6U0pFR5soQ6gMRMRHr14IOc++S3/90YmL143AqvWvqpUAKfTSVZWFqWlevDUWERGRpKSkoLdbj+m+TUx1KJrUiz3n9eXO99azbOLf+Km07qFOiSlGpWsrCzi4uJITU3F2zaXCiVjDHl5eWRlZdG5c+djWoZeSqqDi9NSOGdAOx5btJnMXQdCHY5SjUppaSmtWrXSpNBIiAitWrU6rjM4TQx1ICL8Y1J/2raI5LZXV1JYqpXsKVWZJoXG5Xi/j2C3+fyCiOSIyNpqpseLyAciskpE1onItcGM53jER9n592WDyNp/iL+8W+XmKKVUsxDsM4Z5wPgapt8MrDfGDAROA2aKSESQYzpmaamJ/H5MD97N3MPbK/QRVqVU8xTUxGCMWQzk11QEiBPveU+sr6wrmDEdr1vO6Mbw1ET+8u5aduwrDnU4SikgNjY26OuYPXs2CxYsCPp6qjJv3jz27NnTYOsL9T2Gp4HewB5gDfB7Y4ynqoIiMlVE0kUkPTc3dNVUWC3C45cNwma18PvXVlLuqjJcpVQT5HZX37TvtGnTmDx5ckjWHW6JYRyQCbQHBgFPi0iLqgoaY+YYY9KMMWlJSUkNGeMRkltG8fCF/VmVVcDMzzeFNBalVKBHHnmEYcOGMWDAAO677z7/+PPPP5+hQ4fSt29f5syZ4x8fGxvLHXfcwcCBA1m6dCmxsbH8+c9/ZuDAgYwcOZK9e/cCMGPGDB599FEATjvtNO666y6GDx9Ojx49WLJkCQCHDh3ikksuoU+fPkyaNIkRI0aQnp5ebayHr/uBBx5g2LBh9OvXj6lTp2KMYeHChaSnp3PFFVcwaNAgSkpKyMjI4NRTT2Xo0KGMGzeO7Ozsev0bhjoxXAu8bby2AtuBXiGOqU7G92vH5cM78uw32/h2y75Qh6OUAhYtWsSWLVv48ccfyczMJCMjg8WLFwPwwgsvkJGRQXp6Ok8++SR5eXkAFBcXM2LECFatWsWoUaMoLi5m5MiRrFq1ilNOOYXnnnuuynW5XC5+/PFHnnjiCe6//34AZs2aRUJCAuvXr+fBBx8kIyOjxngPX/ctt9zC8uXLWbt2LSUlJXz44YdcdNFFpKWl8fLLL5OZmYnNZuPWW29l4cKFZGRk8Lvf/Y4///nP9fhXDH1i2AmMARCRtkBPYFtIIzoKfz23D93axPKHNzLJKyoLdThKhb1FixaxaNEiBg8ezJAhQ9i4cSNbtmwB4Mknn/SfBezatcs/3mq1cuGFF/qXERERwbnnngvA0KFD2bFjR5XruuCCC44o8+2333LZZZcB0K9fPwYMGFBjvIev+6uvvmLEiBH079+f//3vf6xbt+6IeTZt2sTatWsZO3YsgwYN4m9/+xtZWfX7MExQ33wWkVfxPm3UWkSygPsAO4AxZjbwIDBPRNYAAtxljGkyh99REVaevGww5//nO6YvXM3cq9P0eW6lQsgYwz333MMNN9wQMP7rr7/miy++YOnSpURHR3Paaaf5XwCLjIzEarX6y9rtdv/v2Gq14nJV/TyMw+GotUxtKq+7tLSUm266ifT0dDp06MCMGTOqfEnNGEPfvn1ZunTpMa2zLoL9VNLlxph2xhi7MSbFGDPXGDPblxQwxuwxxpxljOlvjOlnjHkpmPEEQ5/2LbhnQi/+tzGH+d/vCHU4SoW1cePG8cILL1BUVATA7t27ycnJoaCggISEBKKjo9m4cSPLli0LyvpPPvlk3njjDQDWr1/PmjVr6jxvRRJo3bo1RUVFLFy40D8tLi6OwsJCAHr27Elubq4/MTidzirPLI6H1pVUD645KZUlW/bxj483MrxzK/q0r/L+uVIqyM466yw2bNjAiSeeCHhv7r700kuMHz+e2bNn07t3b3r27MnIkSODsv6bbrqJq6++mj59+tCrVy/69u1LfHx8neZt2bIl119/Pf369eOEE05g2LBh/mnXXHMN06ZNIyoqiqVLl7Jw4UJuu+02CgoKcLlc3H777fTt27fetkOaYtOVaWlppqY7/aGQV1TG+H8voUWkjQ9vHU1UhLX2mZRqBjZs2EDv3r1DHUaj4Ha7cTqdREZG8tNPP3HmmWeyadMmIiIa/r3dqr4XEckwxqTVNm+obz43G61iHTx+ySC27SvmgQ/XhzocpVQIHDp0iFGjRjFw4EAmTZrErFmzQpIUjledLiWJyMXAp8aYQhG5FxgC/M0YsyKo0TUxo7q3ZuopXXj2m22c3K0V5w5oH+qQlFINKC4ursr3FkaMGEFZWeCTiy+++CL9+/dvqNCOSl3vMfzFGPOmiIwCzgQeAZ4BRgQtsibqjrE9Wb49n+lvrqZbm1h6naD3G5QKdz/88EOoQzgqdb2UVPGu9jnAHGPMR0DTOz9qABE2C89cOZS4SBtTF2Rw4FB5qENSSqmjUtfEsFtEngUuBT4WEcdRzBt22raI5Jkrh5JdUMKtr67E7Wl6N/iVUuGrrjv3S4DPgHHGmANAIjA9aFE1A0M7JfDgxH4s2bKPf322MdThKKVUndU1MbQDPjLGbBGR04CLgR+DFlUzcdnwjlwxwluf0gerGq5mRKXCjdVqZdCgQfTt25eBAwcyc+ZMPJ7aaz6ePn06ffv2Zfr0YzvOrajue8eOHbzyyit1micjI4P+/fvTrVs3brvtNqp6ZcAYw2233Ua3bt0YMGAAK1b8+pzP+PHjadmypb/ajmCoa2J4C3CLSDdgDtABqNtfIczd95u+pHVKYPrCVazfczDU4SjVLEVFRZGZmcm6dev4/PPP+eSTT/wV29Vkzpw5rF69mkceeeS41n80ieHGG2/kueeeY8uWLWzZsoVPP/30iDKffPKJf/qcOXO48cYb/dOmT5/Oiy++eFzx1qauicFjjHEBFwBPGWOm4z2LULWIsFmYdeUQWkZFMPXFdPYX681opYKpTZs2zJkzh6effhpjDG63m+nTp/ur4n722WcBOO+88ygqKmLo0KG8/vrrfPDBB4wYMYLBgwdz5plnVlndNngrxzu8Yr27776bJUuWMGjQIB5//PFqY8vOzubgwYOMHDkSEWHy5Mm8++67R5R77733mDx5MiLCyJEjOXDggL9q7TFjxhAXF3e8f6Ya1fVxVaeIXA5MBn7jG2cPTkjNT5u4SGZfNZRLZi/llldXMP/a4diseu9eNT/3f7Cu3s+M+7RvwX2/ObrqHrp06YLb7SYnJ4f33nuP+Ph4li9fTllZGSeffDJnnXUW77//PrGxsWRmZgKwf/9+li1bhojw/PPP869//YuZM2fWaX0PPfQQjz76KB9++CEAe/bsYcqUKXz88ccB5Xbv3k1KSor/c0pKCrt37z5iebt376ZDhw5HlGvXrmGOx+uaGK4FpgF/N8ZsF5HOQHDPZZqZQR1a8rdJ/bhz4Woe/nQjfz6nT6hDUiosLFq0iNWrV/srpSsoKGDLli107tw5oFxWVhaXXnop2dnZlJeXHzH9aLRv3/6IpNCU1CkxGGPWi8gfgR4i0g/YZIx5OLihNT+XpHVg7e4CnluynX7J8UwclBzqkJSqV0d7ZB8s27Ztw2q10qZNG4wxPPXUU4wbN67GeW699Vb+7//+j/POO4+vv/6aGTNmAGCz2QJuZFdVFXZdJScnB7SdkJWVRXLykfuB5ORkdu3aVWu5YKnT9Qzfk0hbgP8As4DNInJKEONqtv5ybh+Gd07kzoWrWbu7INThKNXs5ObmMm3aNG655RZEhHHjxvHMM8/gdDoB2Lx5M8XFxUfMV1BQ4N/5zp8/3z8+NTXV/1TQihUr2L59+xHzVq4Wuybt2rWjRYsWLFu2DGMMCxYsYOLEiUeUO++881iwYAHGGJYtW0Z8fHyDXUaCut98ngmcZYw51RhzCt62mqu/w6KqZbdamHXFEBJjIrjhxQxt+U2pelBSUuJ/XPXMM8/krLPO8rf3PGXKFPr06cOQIUPo168fN9xwQ5UN68yYMYOLL76YoUOH0rp1a//4Cy+8kPz8fPr27cvTTz9Njx49jph3wIABWK1WBg4cyOOPP86ePXuYMGFClbHOmjWLKVOm0K1bN7p27crZZ58NwOzZs5k9ezYAEyZMoEuXLnTr1o3rr7+eWbNm+ecfPXo0F198MV9++SUpKSl89tlnx/6Hq0adqt0WkdXGmAG1jWsojbHa7aO1OusAF81eytCOCbx4nd6MVk2XVrvdODVEtdvpIvK8iJzm654Dat0zi8gLIpIjImtrKHOaiGSKyDoR+aaO8TR5A1Ja8s9J/Vm6LY9/fKxvRiulGo+6JoYbgfXAbb5uvW9cbeYB46ubKCIt8d6zOM8Y0xfvG9Vh48KhKVx7ciovfLedt1fUb2PeSil1rOr6VFIZ8JivqzNjzGIRSa2hyG+Bt40xO33lc45m+c3Bnyb0ZkP2Qe5+ew1JcQ5Gd08KdUhKqTBX4xmDiKwRkdXVdfWw/h5Agoh8LSIZIjK5hlimiki6iKTn5ubWw6obB+/N6KF0aR3DdfPT+WpT2OVGpVQjU9sZQ/Bqafp1/UOBMUAUsFRElhljNh9e0BgzB289TaSlpTWreqwTYyJ49fqRXDn3B25YkMGsK4ZwZp+2oQ5LKRWmajxjMMb8XFNXUU5Elh7j+rOAz4wxxcaYfcBiYOAxLqtJS4iJ4JUpI+ndLo4bX87g07W/hDokpVSYqq9nJCOPcb73gFEiYhORaLxNhW6op5ianPhoOy9OGUG/5HhufmUFH63ODnVISjUJFdVfB1N+fj5jx46le/fujB07lv3791dZbv78+XTv3p3u3bsHvChXXXXb1S1348aNnHjiiTgcjoBK/BpCfSWGKi/tiMirwFKgp4hkich1IjJNRKYBGGM2AJ8Cq/G27/C8MabaR1vDQYtIOwt+N5whHVty22sreS/zyAq2lFIN76GHHmLMmDFs2bKFMWPG8NBDDx1RJj8/n/vvv58ffviBH3/8kfvvv9+/o6+uuu3qlpuYmMiTTz7JH//4x4bbSJ+gvlVljLncGNPOGGM3xqQYY+YaY2YbY2ZXKvOIMaaPMaafMeaJYMbTVMRF2pl37XCGpSbwh9czeStDH2VV6mhlZmYycuRIBgwYwKRJk9i/fz85OTkMHToUgFWrViEi7Ny5E4CuXbty6NChapf33nvvcfXVVwNw9dVXV1ld9meffcbYsWNJTEwkISGBsWPH8umnn9ZY3XZ1y23Tpg3Dhg3Dbm/4iqzrWrtqbaSelqN8Yhw2/nvNcKYsWM4fF67C7TFcMqxD7TMqFUqf3A2/rKnfZZ7QH84+8ui8NpMnT+app57i1FNP5a9//Sv3338/TzzxBKWlpRw8eJAlS5aQlpbGkiVLGDVqFG3atCE6OpoJEybw/PPP0759+4Dl7d27119f0QknnOBvr6Gy6qrLrqm67bost6HVV2K4qp6WoyqJirAy9+phTH0xgzvfWo3T4+GKEZ1CHZZSjV5BQQEHDhzg1FNPBbxH4hdf7H1/9qSTTuK7775j8eLF/OlPf+LTTz/FGMPo0aMB6lRdtoggUv/Hw8Fa7tGqMTGISCFV3z8QwBhjWuAdCOv7AsEUabcy56qh3PTyCv78zlpcbsPVJ6WGOiylqnYMR/YN7ZRTTmHJkiX8/PPPTJw4kYcffhgR4ZxzzqlxvrZt25KdnU27du3Izs6mTZs2R5RJTk7m66+/9n/OysritNNOq7G67bost6HV9rhqnDGmRRVdXEVSUMEXabcy+8qhjO3TlvveX8fzS7aFOiSlGrX4+HgSEhJYsmQJAC+++KL/7GH06NG89NJLdO/eHYvFQrqDYHEAAB0USURBVGJiIh9//DGjRo2qcZnnnXee/ymj+fPnV1ld9rhx41i0aBH79+9n//79LFq0iHHjxtVY3XZdltvgjDF17oA2QMeK7mjmrc9u6NChJhyVu9zmxpfSTae7PjTPfL011OEoZYwxZv369aEOwYiISU5O9nczZ840K1euNCNGjDD9+/c3EydONPn5+f7yKSkp5tlnnzXGGPP3v//d9O/f3z/t7LPPNrt37z5iHfv27TNnnHGG6datmxkzZozJy8szxhizfPlyc9111/nLzZ0713Tt2tV07drVvPDCC/7xy5cvN3379jVdunQxN998s/F4PDUuNzs72yQnJ5u4uDgTHx9vkpOTTUFBQZ3/JlV9L0C6qcM+tq7Vbp+Ht02G9kAO0AnYYLwV3zW45lDt9rFyuT384Y1VfLBqD3eM7cGtY7qHOiQV5rTa7cbpeKrdruvN5weBkcAXxpjBInI6cOVRR6qOm81q4fFLBmK3CDM/38whp5s7x/VsFDeslFLNQ10Tg9MYkyciFhGxGGO+EhF95yBEbFYLj148kMgIK898/RMl5W7+em4fLBZNDkqp41fXxHBARGKBJcDLIpIDHNloqmowFovw9/P7EW238vy32ykuc/HQhQOwanJQSh2nuiaGr4B44Pd4LyHFAw8EKyhVNyLCn8/pTYzDxr+/3EKJ083jlw7Crs2EKqWOQ10Tgw1YBOQDrwOvG2PyghaVqjMR4Q9jexDjsPKPjzdS6nTz9G+HEGm3hjo0pVQTVadDS2PM/b4nkG4G2gHfiMgXQY1MHZWpp3TlwfP78cWGHK6bv5ziMleoQ1JKNVFHe80hB/gFyMP7ToNqRK4a2YmZFw9k6U95TH7hRwpKnKEOSakGcXi12/PmzeOWW24BYPbs2SxYsKDG+SuXr6uysjIuvfRSunXrxogRI9ixY8cRZTZt2sSgQYP8XYsWLXjiCe9zOzNmzCA5Odk/rS5VcTSUOl1KEpGbgEuAJOBN4HpjzPpgBqaOzYVDU4iOsHLbayu54vllLPjdCBJjIkIdllIhM23atKAsd+7cuSQkJLB161Zee+017rrrLl5//fWAMj179iQzMxMAt9tNcnIykyZN8k//wx/+EJJqtWtT1zOGDsDtxpi+xpgZmhQat7P7t2POVWls2VvEpc8uJedgaahDUipkZsyY4W/oZvny5QwYMIBBgwYxffp0+vXr5y+3Z88exo8fT/fu3bnzzjtrXW7l6rIvuugivvzyS2p6YfjLL7+ka9eudOrU+CvCrNMZgzHmnmAHourX6b3a8N9rhzFlfjoXP7uUl6eMICUhOtRhqWbu4R8fZmP+xnpdZq/EXtw1/K4ay5SUlDBo0CD/5/z8fM4777wjyl177bU899xznHjiidx9990B0zIzM1m5ciUOh4OePXty66230qFDB6ZMmcK0adNISwt8YbhyFds2m434+Hjy8vJo3bp1lTG+9tprXH755QHjnn76aRYsWEBaWhozZ84kISGhxu1sKEF9rlFEXhCRHBGpsfZVERkmIi4RuSiY8YSbk7q25qUpI9hfXM4ls5eyLbco1CEpFRRRUVFkZmb6uwceOPJp+gMHDlBYWMiJJ54IwG9/+9uA6WPGjCE+Pp7IyEj69OnDzz97m7V//vnnj0gKR6u8vJz333/fX/U3eFt0++mnn8jMzKRdu3bccccdx7WO+lRf7TFUZx7wNFDtnR8RsQIP430cVtWzIR0TeHXqSCbP/ZFLnl3GM1cOYVhqYqjDUs1UbUf2jZnD4fAPW61WXK6an+xLTk5m165dpKSk4HK5KCgooFWrVlWW/eSTTxgyZAht27b1j6s8fP3113Puuece5xbUn2A37bkY77sPNbkVeAvvE08qCPq2j+f1G07EYbNw8eyl3PhSBjv26YvrKry0bNmSuLg4fvjhB8B7aed4VK4ue+HChZxxxhnV1ln26quvHnEZKTs72z/8zjvvBNzvCLWQviIrIsnAJOCZUMYRDrq1ieXz/zuFP5zZg2825zL28W944IP17C8uD3VoSjWYuXPncv311zNo0CCKi4uJj4+vdZ4pU6ZQVW3O1113HXl5eXTr1o3HHnuMhx7yNlK0Z88eJkyY4C9XXFzM559/zgUXXBAw/5133kn//v0ZMGAAX331FY8//vhxbl39qVO128e1ApFU4ENjzBHpUETeBGYaY5aJyDxfuYXVLGcqMBWgY8eOQyuu/6mjl3OwlMe/2Mzry3cR67Bx6xndmXxSJxw2fVtaHb2mVO12UVGR/52Hhx56iOzsbP7973+HOKrgOJ5qt0NdqU4a8JqI7AAuAmaJyPlVFTTGzDHGpBlj0pKSkhoyxmanTYtI/nnBAD75/SkM6ZTA3z/ewJmPfcMHq/bU+LidUk3dRx99xKBBg+jXrx9Llizh3nvvDXVIjVJIzxgOKzePGs4YKgvnhnqCYcmWXP7+0QY2/lLIoA4tufec3qTpDWpVR03pjCGcNNozBhF5FVgK9BSRLBG5TkSmiUhwXkVUx2R09yQ+um00/7poANkFJVykN6jVUdIzzcbleL+PoJ8xBIOeMQTPoXIXzy/ZzuxvfsLp9nDlyE7cfmYP4qPsoQ5NNVLbt28nLi6OVq1aaUuCjYAxhry8PAoLC+ncuXPAtLqeMWhiUFXKKSzl8c+38PrynSTGRPCnCb2ZNDhZf/jqCE6nk6ysLEpLteqVxiIyMpKUlBTs9sADOk0Mql6s3V3Ave+uJXPXAYZ3TuRv5/ejR9u4UIellDoGjeIeg2r6+iXH8/aNJ/HPC/qzeW8hE/69hH98vEHbe1CqGdPEoGplsQiXD+/I/+44jQuHpDBn8TbOfOwbPlmTrTcdlWqGNDGoOkuMieDhiwbw1o0n0jI6ghtfXsHV/13Odn16SalmRRODOmpDOyXywS0nc99v+rDi5/2Me3wxj32+mVKnO9ShKaXqgSYGdUxsVgvXntyZ/91xKmf3P4Env9zCWY8v5quNWheiUk2dJgZ1XNq0iOTflw3mlSkjsFuFa+ct5/9ez8Tt0XsPSjVVmhhUvTipW2s++f0p3HpGN95euZsZ76/TG9NKNVHBbqhHhZEIm4U7zupJmcvDnMXbSE6IYtqpXUMdllLqKGliUPXu7vG92HOghIc+2Ui7+EgmDkoOdUhKqaOgiUHVO4tFmHnJQHILy/jjm6tIinNwUteqG0hXSjU+eo9BBYXDZmXOVWmktorhhgUZbPzlYKhDUkrVkSYGFTTx0Xbm/W44URFWrv3vcrILSkIdklKqDjQxqKBKbhnFf68dRmGpi2v/u5yDpc5Qh6SUqoUmBhV0fdvH88yVQ9iaU8SNL2VQ7vKEOiSlVA00MagGMbp7Eg9fOIDvtuZx11ur9R0HpRqxYDft+YKI5IjI2mqmXyEiq0VkjYh8LyIDgxmPCq0Lh6bwx7N68M7K3Ty6aFOow1FKVSPYZwzzgPE1TN8OnGqM6Q88CMwJcjwqxG4+vRuXD+/Af776iZeW/RzqcJRSVQjqewzGmMUiklrD9O8rfVwGpAQzHhV6IsKDE/vxS0Epf31vLSe0iOTMPm1DHZZSqpLGdI/hOuCTUAehgs9mtfD0b4fQLzmeW15dQeauA6EOSSlVSaNIDCJyOt7EcFcNZaaKSLqIpOfm5jZccCooYhw25l49jKQ4B9fNW86mXwpDHZJSyifkiUFEBgDPAxONMXnVlTPGzDHGpBlj0pKSkhouQBU0SXEO5l87HAOc8+QSHvhgPQWH9D0HpUItpIlBRDoCbwNXGWM2hzIWFRpdkmL57PZTuDitA/O+386pj37FvO+243Truw5KhYoE83lyEXkVOA1oDewF7gPsAMaY2SLyPHAhUPF4issYk1bbctPS0kx6enpQYlahsyH7IH/7aD3fbc2ja1IM957bh9N7tgl1WEo1GyKSUZd9bFATQ7BoYmi+jDF8sSGHf3y8ge37ijmlRxL3ntObHm3jQh2aUk1eXRNDyO8xKFWZiDC2T1s+u/0U7j2nN5k793P2v5fwl3fXkl9cHurwlAoLmhhUoxRhszBldBe+nn46V4zoyCs/7uTUR77i+SXbtK4lpYJME4Nq1BJjInhgYj8+/f1ohnRM4G8fbeCsx7/hs3W/4PE0vcugSjUFeo9BNSlfbcrh7x9tYGtOER0To7l0WAcuGppC2xaRoQ5NqUZPbz6rZsvp9vDR6mxeW76TZdvysQic0asNlw7ryOk9k7BZ9URYqapoYlBhYfu+Yt5I38XCjCxyC8toE+fgoqEpXJLWgdTWMaEOT6lGRRODCitOt4evN+Xy+vKd/G9jDh4DI7skctmwjozvdwKRdmuoQ1Qq5DQxqLD1S0Epb63I4vXlu9iZf4gWkTYmDU7mipGd9H0IFdY0Maiw5/EYlm3L47Xlu/h07S+4PB4mn5jKHWf1IC7SHpT1bc4ppGfbOESk3pev1PGqa2IIansMSoWSxSKc1K01J3VrTX5xOY99von5S3fw8Zps/vqbPpzTv1297MCNMXyzOZd/fbqJ9dkHGd/3BB65eEBQko9SDUEf31BhITEmgr+d3593bjqZNi0c3PLKSia/8CM79hUf13JX7NzPZXOWcc1/l1NY5uSak1L5fMNeJv7nO7bs1arEVdOkl5JU2HF7DC8u3cGjizZT7vZw02ldmXZq16O6Qb01p5BHPtvEZ+v20jo2glvP6M7lwzsSYbOw9Kc8bn11BYfK3fzrogGcO6B98DZGqaOg9xiUqsXeg6U8+OF6PlydTefWMTwwsS+ju9fc1seeAyU88cVmFmZkER1h4/rRXZgyujMxjsCrsr8UlHLTyxms2HmAKaM6c9fZvbDr+xUqxDQxKFVHS7bk8pd317Ij7xC/Gdiev5zTmzaHvUm9v7icWV9vZf7Sn8HAlSM7cfPpXWkV66h2ueUuD//4eAPzvt/B8M6JPP3bwbSJ0ze0VehoYlDqKJQ63cz+5idmff0TDquFO87qwVUnplLmcvPf73Yw++ufKCp3ccHgFP4wtjspCdF1Xva7K3dz99uraRFpZ9YVQ0hLTQzilihVPU0MSh2D7fuK+et7a1myZR+927VgX1EZuYVlnNm7LdPH9aTnCcf2HsSG7IPc+FIGWftLuPec3lx9Uqo+0qoanCYGpY6RMYaP1mTzyGebaNsikjvH9ayXo/yCEid3vLGKLzbsZeKg9vzzgv5ER+gT46rhNIrEICIvAOcCOcaYflVMF+DfwATgEHCNMWZFbcvVxKCaKo/H8Mw3P/Hook30aBPH7KuG0lnrdFINpLG04DYPGF/D9LOB7r5uKvBMkONRKqQsFuHm07sx/9rh5BSWct5T37Jo3S+hDkupAEFNDMaYxUB+DUUmAguM1zKgpYi0C2ZMSjUGp/RI4oNbR9E5KYapL2bw1JdbaIqXdVXzFOoHq5OBXZU+Z/nGKdXspSRE88YNJ3LB4GRmfr6ZW15ZyaFyV6jDOibGGD5dm03mrgOhDkXVgyZz50tEpuK93ETHjh1DHI1S9SPSbmXmJQPp1S6Of36ykR15xcyZnEZyy6hQh1ZnpU43f31vLW+kZxHrsPHOTSfRXWuxbdJCfcawG+hQ6XOKb9wRjDFzjDFpxpi0pKSa305VqikREaae0pUXrh7GzrxDTHz6WzJ+rukKbOOxK/8QFz7zPW+kZzFlVGeiIqxcNz+d/OLyUIemjkOoE8P7wGTxGgkUGGOyQxyTUiFxeq82vHPzScQ6bFw2ZxlvpO+qfaYQ+mpTDuc+9S078w8x9+o07j23D3OuGsovB0u58aUMyl2eUIeojlFQE4OIvAosBXqKSJaIXCci00Rkmq/Ix8A2YCvwHHBTMONRqrHr1iaO924exYjOrbhz4Woe/HA9Lnfj2sF6PIZ/f7GF381bTvuWUXx46yjG9G4LwOCOCTxy0QB+2J7Pfe+v0xvqTVRQ7zEYYy6vZboBbg5mDEo1NfHRduZdO4y/fbSBud9uZ/PeQp6+fAjx0aFv36HgkJPbX1/JV5tyuWBwMn+f1J+oiMBaaScOSmbz3kL+89VP9GwbyzUndw5RtOpYhfpSklKqCjarhRnn9eWhC/qzbFsek2Z9x0+5RSGNad2eAn7z9Ld8u3UfD57fj5mXDDwiKVS4Y2xPxvZpywMfrmfx5twGjlQdL00MSjVilw3vyCvXj6SgxMn5//mOrzflhCSOtzKyuGDW95S7PLx+w4lcNbJTjXU9WSzCE5cOokfbOG5+ZUXIk5o6OpoYlGrkhqUm8t4tJ5OSEM3v5i3nucXbGuzafZnLzb3vruGON1cxpGMCH942iiEdE+o0b4zDxvNXpxFhtTBlfjoHDumTSk2FVqKnVBNRXObij2+u4pO1v9A+PpKkFpG0jokgMSaCVrEOWsdG0Co2glYxDlrFRtA61kFCdAQRtmM7/ttzoIQbX17Bql0HuOHULkw/qye2Y2hsKH1HPr997geGdU5g3rXDtcGiEGoUlegFiyYGFa48HsNLP/zMyp0H2FdURl5ROfnF5eQVl+F0V/1bjo+ykxgTQYTVgs0q2CyCzWrBahHsVsFqsWC3iG+at4zVInyzKZcyl4dHLhrA2f2Pr6aaN9N3MX3haiaf2IkHJh5Rn6aqhttj2FdUxp4DJWQXlLLnQAkju7SiX3L8MS2vromhybz5rJTyXruffGIqk08MHG+M4WCpi7yiMvKKy8krKmNfUbkvcXjHOd0eXG6Dy2NwebzDpU4PLo8bl9uD22Nw+vuGzq1jeOjCAXRrE3vccV+c1oEtOUXMWbyN7m3juGpkp+NeZlNnjCG/uNy/w88uKGVPQQnZB0rJLihhz4FS9h4sxeUJTPj3nN3rmBNDXWliUKoZEBHio+zER9np0kgrBrhrfC+25hQx4/11dG0dw0ndWoc6pJBZnXWAu99aw/rsgwHj7VahXXwU7eIjGd45kXbxkbRrGUX7+EjaxUfRvmUk8VHBf2xZLyUppRpMYamTC2Z9T05hGe/dfDKpYdYWRUm5m8c+38Tcb7eTFOfgulGd6ZgY7U0GLSNpHePAYgley356j0Ep1SjtzDvExP98S2JMBO/cfDItIms+Ai4uc5FbWMa+Im/ndBv6JceT2iq6STWP+v3Wfdz99hp25h/i8uEdufvsXg1y9F+Z3mNQSjVKHVtF88yVQ7ny+R+45ZWV/HZ4B3ILy8gtKvfu/AvLyPUlgX2F5ZQ43VUuJz7KzoCUeAZ1aMnAlJYM7NCSpDhHA29N7QoOOfnHxxt4PX0Xqa2iefX6kZzYtVWow6qRnjEopULi1R93cs/ba/yfRSAx2vuYbVKc9/Hb1rEOWsc5SPL1W8dGALB2dwGZuwpYtesAm/YW4vbdoE1uGcXADvH+RNE/OZ4YR+iOfz9dm81f3ltHfnE5U0Z35g9n9iDSXvXb4g1BLyUppRq9zXsLcbkNreMiSIyOOKb3JErK3azbU0DmrgOsyvImi535hwCwCHRvE0eHxCgibBYcNisOmwWHzRLwOcI3zmG3EmG1EBVhpUtSDN2SYo8pppyDpfz1vXV8uu4X+rRrwb8uGhD0J4nqQi8lKaUavR710KBPVISVtNRE0lIT/ePyi8tZlXWAVbu8XXZBKWUuD+UuD2Uut3+41OnGU8OxscNmoXe7FvRLbkG/9vH0S46nR9u4al8aNMbwZnoWf/toPaUuD3eO78n1o7s0uZf69IxBKRXWXG4P5W4PZU4PZb7EUVzmZktOIWuyCli7p4B1uw9SWOZtdtVuFXqeEEf/5Hj6+pJFrxPiyDlYxj3vrOa7rXkM75zIQxf0p0vS8b8DUp/0UpJSStUTj8ewM/8Qa/cUsGa3N1Gs2V1AQYkTAKtFsIoQYbNwz4ReXD6sY1AfOz1WeilJKaXqicUipLaOIbV1DOcOaA94Lxtl7S9h3Z4C1u4+SFGZixtO7UK7+KbTXnd1NDEopdQxEBE6JEbTITGa8f2Ory6pxibod0REZLyIbBKRrSJydxXTO4rIVyKyUkRWi8iEYMeklFKqesFu89kK/Ac4G+gDXC4ifQ4rdi/whjFmMHAZMCuYMSmllKpZsM8YhgNbjTHbjDHlwGvAxMPKGKCFbzge2BPkmJRSStUg2IkhGdhV6XOWb1xlM4ArRSQL+Bi4taoFichUEUkXkfTcXG1DVimlgqUxvHVxOTDPGJMCTABeFJEj4jLGzDHGpBlj0pKSGmm9wkop1QwEOzHsBjpU+pziG1fZdcAbAMaYpUAkEL4VtSulVIgFOzEsB7qLSGcRicB7c/n9w8rsBMYAiEhvvIlBrxUppVSIBDUxGGNcwC3AZ8AGvE8frRORB0TkPF+xO4DrRWQV8CpwjWmKr2MrpVQz0SSrxBCRXODnY5y9NbCvHsNpasJ5+8N52yG8t1+33auTMabWm7RNMjEcDxFJr0tdIc1VOG9/OG87hPf267Yf3bY3hqeSlFJKNSKaGJRSSgUIx8QwJ9QBhFg4b384bzuE9/brth+FsLvHoJRSqmbheMaglFKqBpoYlFJKBQirxFBb2xDNmYjsEJE1IpIpIs2+XVQReUFEckRkbaVxiSLyuYhs8fUTQhljsFSz7TNEZLfv+89sru2eiEgHX/su60VknYj83jc+XL776rb/qL7/sLnH4GsbYjMwFm8tr8uBy40x60MaWAMRkR1AmjEmLF7yEZFTgCJggTGmn2/cv4B8Y8xDvgODBGPMXaGMMxiq2fYZQJEx5tFQxhZsItIOaGeMWSEicUAGcD5wDeHx3Ve3/ZdwFN9/OJ0x1KVtCNVMGGMWA/mHjZ4IzPcNz8f7g2l2qtn2sGCMyTbGrPANF+KtiieZ8Pnuq9v+oxJOiaEubUM0ZwZYJCIZIjI11MGESFtjTLZv+BegbSiDCYFbfM3nvtBcL6VUJiKpwGDgB8Lwuz9s++Eovv9wSgzhbpQxZgjeZlZv9l1uCFu+ihrD4zqq1zNAV2AQkA3MDG04wSUiscBbwO3GmIOVp4XDd1/F9h/V9x9OiaEubUM0W8aY3b5+DvAO3ktr4Wav7xpsxbXYnBDH02CMMXuNMW5jjAd4jmb8/YuIHe9O8WVjzNu+0WHz3Ve1/Uf7/YdTYqhL2xDNkojE+G5EISIxwFnA2prnapbeB672DV8NvBfCWBpUxU7RZxLN9PsXEQHmAhuMMY9VmhQW331123+033/YPJUE4HtE6wnACrxgjPl7iENqECLSBe9ZAoANeKW5b7uIvAqchrfK4b3AfcC7eFsL7Ii32vZLjDHN7iZtNdt+Gt7LCAbYAdxQ6Zp7syEio4AlwBrA4xv9J7zX2cPhu69u+y/nKL7/sEoMSimlahdOl5KUUkrVgSYGpZRSATQxKKWUCqCJQSmlVABNDEoppQJoYlCqgYnIaSLyYajjUKo6mhiUUkoF0MSgVDVE5EoR+dFXf/2zImIVkSIRedxX1/2XIpLkKztIRJb5Kil7p6KSMhHpJiJfiMgqEVkhIl19i48VkYUislFEXva9sapUo6CJQakqiEhv4FLgZGPMIMANXAHEAOnGmL7AN3jfKgZYANxljBmA963TivEvA/8xxgwETsJbgRl4a728HegDdAFODvpGKVVHtlAHoFQjNQYYCiz3HcxH4a14zQO87ivzEvC2iMQDLY0x3/jGzwfe9NVPlWyMeQfAGFMK4Fvej8aYLN/nTCAV+Db4m6VU7TQxKFU1AeYbY+4JGCnyl8PKHWudMmWVht3ob1E1InopSamqfQlcJCJtwN9mcCe8v5mLfGV+C3xrjCkA9ovIaN/4q4BvfC1oZYnI+b5lOEQkukG3QqljoEcpSlXBGLNeRO7F2+qdBXACNwPFwHDftBy89yHAW5XzbN+OfxtwrW/8VcCzIvKAbxkXN+BmKHVMtHZVpY6CiBQZY2JDHYdSwaSXkpRSSgXQMwallFIB9IxBKaVUAE0MSimlAmhiUEopFUATg1JKqQCaGJRSSgX4fyxxW9b22bqxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFGex1GxVxIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}